<!-- HTML header for doxygen 1.8.15-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ARA SDK 2.3.0: Content Reading</title>
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="shortcut icon" sizes="16x16" href="./favicon.ico">
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<link href="DoxygenStyleSheet.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="ARA_Logo.png" height="50px"/></td>
   <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.svg"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('group___content___reading.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#groups">Subpages</a>  </div>
  <div class="headertitle">
<div class="title">Content Reading</div>  </div>
</div><!--header-->
<div class="contents">
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="groups"></a>
Subpages</h2></td></tr>
<tr class="memitem:group___model___content___updates"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___model___content___updates.html">Content Updates</a></td></tr>
<tr class="memdesc:group___model___content___updates"><td class="mdescLeft">&#160;</td><td class="mdescRight"> <br>                               There are several levels of abstraction when analyzing musical recordings. Initially, there is the signal in its "physical" form. On the next level, the signal interpreted as a series of musical events - the notes played when creating the signal. These notes and their relationship in time and pitch can be interpreted further, leading to abstractions like tempo, bar signatures, key signatures, tuning and chords.  <br>                               Updates may happen on any of these levels, both independently or concurrently. In the most simple but most unlikely case, the signal is completely replaced, and all the higher abstractions therefore also invalidated. This also means that all user edits done in an audio modification will be lost. More likely is a minor modification of the signal, such as applying a high pass filtering to remove rumble in the audio source. This will not change any higher abstractions (all notes etc. remain the same), so any edits inside the audio modification or any notation of the music based on the analysis will remain intact. Another case is the correction of the analysis by the user. The signal does not change in this case, but mis-detected notes are added or removed so the mid-level abstraction which is considered with the notes changes. Whether or not this also changes higher interpretations such as the detected harmonic structure depends on the case at hand.  <br>                               ARA defines a set of flags that allow to communicate the level of change, which helps to avoid unnecessary flushing of the user edits inside an audio modification and allows for optimizations of the analysis. The flags are providing a guarantee what has NOT changed. This may seem odd at first but if for example a given host does not know about harmonies, it cannot make any assumption about whether these have changed or not. <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:group___model___content___readers__and___content___events"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___model___content___readers__and___content___events.html">Content Readers And Content Events</a></td></tr>
<tr class="memdesc:group___model___content___readers__and___content___events"><td class="mdescLeft">&#160;</td><td class="mdescRight"> <br>                               Reading content description follows the same pattern both from the host and from the plug-in side. ARA establishes iterator objects called content reader to access the data in small units called content events. There are several types available, each defining a certain abstract representation of its associated events.  <br>                               Upon creation, content readers are bound to a given content type and to an object of which the content shall be read. Optionally the reader can be restricted to only cover a given time range. Once created, its event count is queried and the individual events are read, then the reader is disposed of. This is all done immediately, reader objects are only temporary objects that are created and destroyed from the same stack frame.  <br>                               The data pointer returned when reading an event's data remains owned by the content reader and must remain valid until the reader is either another event is read or the reader is destroyed.  <br>                               The events returned by the reader are sorted in an order that depends on the content type, but generally follows their appearance on the timeline. If several events appear at the same (start-)time, their order is not defined and the receiver must apply further sorting if desired.  <br>                               The C++ ARA Library offers convenient content reader classes for host and plug-in developers. Host developers can read plug-in content using ARA::Host::ContentReader, and plug-in developers can use <a class="el" href="group___a_r_a___library___a_r_a_plug___utility___classes.html#class_a_r_a_1_1_plug_in_1_1_host_content_reader" title="Utility class that wraps the host ARAContentAccessControllerInterface.">ARA::PlugIn::HostContentReader</a> to read host content. <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:group___model___timeline"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___model___timeline.html">Timeline</a></td></tr>
<tr class="memdesc:group___model___timeline"><td class="mdescLeft">&#160;</td><td class="mdescRight"> <br>                               ARA expresses musical timing as a mapping between song time measured in seconds and musical time measured in quarter notes. The mapping is created by dividing the timeline into sections of constant musical tempo. These tempo sections are then annotated as a list of tempo sync points, where each point represents both the end of one and the beginning of another section. The location of a tempo sync point is specified both in song time and musical time. The actual tempo of a section can be easily derived from the relationship of the duration of the section in song time and the duration of the section in musical time (note that neither the quarters nor the seconds must necessarily be integer values here): <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:group___model___notes"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___model___notes.html">Notes</a></td></tr>
<tr class="memdesc:group___model___notes"><td class="mdescLeft">&#160;</td><td class="mdescRight"> <br>                               Notes in ARA correspond to what a composer would notate to describe the music. Notes are described by their position in time, their pitch and their relative volume. The pitch can be interpreted as frequency, but ARA also offers a musical description of the pitch very similar to MIDI: it defines the tuning for the overall musical scale and provides an integer number to identify the pitch for each note within this tuning, along with an average detune for each note actually played. ARA pitch numbers match MIDI note numbers, so that the note A4 has the value 69. This note is also used to specify the tuning reference, commonly at 440 Hz. At 440 Hz reference tuning the ARA pitch number 0 thus equals 8.1757989 Hz. Some notes may not have a well-defined pitch, such as percussive notes. For such notes, a frequency of kARAInvalidFrequency and a pitch number of kARAInvalidPitchNumber are used. <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:group___model___tuning___key___signatures__and___chords"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___model___tuning___key___signatures__and___chords.html">Tuning, Key Signatures and Chords (Added In ARA 2.0)</a></td></tr>
<tr class="memdesc:group___model___tuning___key___signatures__and___chords"><td class="mdescLeft">&#160;</td><td class="mdescRight"> <br>                               ARA expresses "western standard" octave-cyclic, 12-tone scales as tunings and key signatures. While some applications such as Melodyne offer a much more complex model that allows for acyclic and/or micro-tonal scales, those models usually don't map well to each others, and introduce a complexity that can not meaningfully be handled by applications with the "main stream" model. Further, there is no standardized musical theory for expressing chords in such scales. Should the actual need to deal with more complex scales arise in the future, a new content type may be added to cover this. <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
