<!-- HTML header for doxygen 1.8.15-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ARA SDK 1.9.15: Implementing ARA</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<link href="DoxygenStyleSheet.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="ARA_Logo.png" height="50px"/></td>
   <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.svg"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('implementing_a_r_a.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Implementing ARA </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#sec_UtilizingExamples">Utilizing the examples and existing products</a><ul><li class="level2"><a href="#autotoc_md7">Mini Host</a></li>
<li class="level2"><a href="#autotoc_md8">Test Host and Test Plug-In</a></li>
<li class="level2"><a href="#autotoc_md9">JUCE_ARA</a></li>
<li class="level2"><a href="#autotoc_md10">Existing Products</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md11">Integrating the ARA SDK into your products</a><ul><li class="level2"><a href="#autotoc_md12">ARAInterface, Debug</a></li>
<li class="level2"><a href="#autotoc_md13">C++ Dispatcher, Utilities</a></li>
<li class="level2"><a href="#autotoc_md14">ARAPlug</a></li>
<li class="level2"><a href="#autotoc_md15">JUCE_ARA</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md16">Mapping the Internal Model to ARA</a><ul><li class="level2"><a href="#autotoc_md17">Dealing with overlapping Playback Regions</a></li>
<li class="level2"><a href="#autotoc_md18">What should Audio Modifications represent in a host?</a></li>
<li class="level2"><a href="#autotoc_md19">What do Region Sequences represent?</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md20">Configuring the rendering</a><ul><li class="level2"><a href="#autotoc_md21">Setting up an ARA Playback Renderer</a></li>
<li class="level2"><a href="#autotoc_md22">Preview Rendering</a></li>
<li class="level2"><a href="#autotoc_md23">Sample rate conversion upon playback</a></li>
<li class="level2"><a href="#autotoc_md24">Playback region head and tail times</a></li>
<li class="level2"><a href="#autotoc_md25">Dealing with denormals</a></li>
<li class="level2"><a href="#autotoc_md26">Caching especially CPU-intense DSP</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md27">Analyzing audio material</a><ul><li class="level2"><a href="#autotoc_md28">What can be analyzed</a></li>
<li class="level2"><a href="#autotoc_md29">Manual adjustments</a></li>
<li class="level2"><a href="#autotoc_md30">Triggering explicit analysis</a></li>
<li class="level2"><a href="#autotoc_md31">Algorithm selection</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md32">Utilizing content exchange</a><ul><li class="level2"><a href="#autotoc_md33">Musical Timing Information, including Content Grade examples</a></li>
<li class="level2"><a href="#autotoc_md34">Notes, including examples of transformations affecting content data</a></li>
<li class="level2"><a href="#autotoc_md35">Chords, Key Signatures and other content types</a></li>
</ul>
</li>
<li class="level1"><a href="#sec_manipulatingTiming">Manipulating the timing</a></li>
<li class="level1"><a href="#autotoc_md36">Content Based Fades</a></li>
<li class="level1"><a href="#sec_ManagingARAArchives">Managing ARA Archives</a></li>
<li class="level1"><a href="#sec_PartialPersistency">Partial Persistency</a><ul><li class="level2"><a href="#autotoc_md37">Copying ARA data between documents</a></li>
<li class="level2"><a href="#autotoc_md38">Audio File Chunks</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md39">User interface considerations</a></li>
<li class="level1"><a href="#autotoc_md40">Choosing Companion APIs</a></li>
<li class="level1"><a href="#sec_vst3Considerations">VST3 specific considerations</a><ul><li class="level2"><a href="#autotoc_md41">setActive vs. setProcessing</a></li>
<li class="level2"><a href="#sec_ViewEmbedding">View Embedding</a></li>
<li class="level2"><a href="#autotoc_md42">View Scaling</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md43">Audio Unit specific considerations</a><ul><li class="level2"><a href="#autotoc_md44">Buffer allocation</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md45">Future ARA development</a></li>
</ul>
</div>
<div class="textblock"><p></p>
<h1><a class="anchor" id="sec_UtilizingExamples"></a>
Utilizing the examples and existing products</h1>
<p>Before starting out with an ARA implementation, we recommend that after reading the <a class="el" href="ara_design_overview.html">ARA Design Overview</a> developers get familiar with some existing ARA products to get a better feel of how ARA works from a users perspective. Melodyne is a particularly useful example because it implements nearly all ARA features and provides extensive online documentation from a user's perspective <a href="https://helpcenter.celemony.com/M5/doc/melodyneStudio5/en/M5tour_CubaseARA_InsertVorbereitungen?env=cubase">online here</a>. <br>                              </p>
<p>Next, we suggest to spend some time reading and experimenting with the accompanying example code to see the API in action before doing some actual design and coding. <br>                               The examples will also continue being useful during coding and testing - having full source code of both the host and the plug-in side examples allows to step through the flow of the program on both sides. Each developer can follow how their calls are typically processed on the other side of the API to catch any mismatches in the interpretation of the ARA model graph and its associated content. <br>                              </p>
<h2><a class="anchor" id="autotoc_md7"></a>
Mini Host</h2>
<p>The mini host example is a great starting point for understanding the basic management and lifetime of the ARA entities. It's written in pure C and walks very briefly through the core functionality of the ARA API. <br>                              </p>
<h2><a class="anchor" id="autotoc_md8"></a>
Test Host and Test Plug-In</h2>
<p>We've also provided a much more elaborate test host which will put an ARA plug-in through various test scenarios, using typical host call sequences and patterns and responding to notifications from the plug-in. <br>                               Ofcourse there's also a matching test plug-in which demonstrates how to iterate over host content, read and analyze audio source samples, and expose analysis results back to the host. It also handles persistence and demonstrates a playback renderer implementation. <br>                               Both the plug-in and host samples contain <a class="el" href="group___debugging.html">checks and assertions</a> to ensure the other party plays by the rules, and should be used often to catch issues during the development process. <br>                              </p>
<h2><a class="anchor" id="autotoc_md9"></a>
JUCE_ARA</h2>
<p>The examples shipping with the ARA SDK cover a wide range of ARA features, but they are all limited to console output and lack a proper user interface. To address this, we've provided an additional experimental <a href="https://github.com/Celemony/JUCE_ARA/tree/develop/examples/Plugins/ARAPluginDemo">JUCE_ARA plug-in demo</a> which is a plug-in with a UI that aims to visualize the ARA graph structure and its associated content in a representation that is close to actual ARA products. <br>                               Even without looking at the source code, this will be a great tool for host and plug-in developers alike to coveniently test how the ARA model graph and its associated content data will be interpreted by plug-ins and to experiment with the ARA UI integration features. <br>                               Since it requires using a custom fork of the extensive JUCE library, this demo is not directly included with the ARA SDK, but it comes with a CMake script to conveniently clone the corresponding git repository, after which the plug-in can be found in <code>JUCE_ARA/examples/Plugins/ARAPluginDemo</code> and be build via the CMake.</p>
<h2><a class="anchor" id="autotoc_md10"></a>
Existing Products</h2>
<p>When developing and testing, it's also wise to regularly review your product's behaviour with existing ARA enabled products, both from an end user's point of view and from a development perspective. <br>                               Plug-in developers should carefully use multiple ARA enabled DAWs when implementing and testing their products, as hosts often exhibit different usage patterns and call sequences that will need to be handled smoothly. <br>                               For host developers, Melodyne is a great benchmark of ARA feature functionality and should be loaded often to ensure a proper host implementation. Melodyne also supports <a class="el" href="group___debugging.html">ARA assertions</a>, even in release builds, making it a great tool for detecting API errors. <br>                              </p>
<h1><a class="anchor" id="autotoc_md11"></a>
Integrating the ARA SDK into your products</h1>
<p>While the ARA API has been defined in C for maximum compatibility, writing low level C code is not convenient. In order to ease ARA development and help creating robust plug-ins and hosts, the ARA library provides several layers of reusable C++ code on top of the underlying bare-bones C API. <br>                              </p>
<p>Each layer of the ARA SDK provides its own level of abstraction and convenience. Picking the API level that's right for you is an important decision. The following overview of each layer shall help you with this task, as should the example code in <code>Examples</code> which illustrates how each layer is used in practice. <br>                              </p>
<h2><a class="anchor" id="autotoc_md12"></a>
ARAInterface, Debug</h2>
<p>The lowest level of abstraction is the "raw" C API contract defined in <code>ARAInterface.h</code>. This layer is header-only and merely defines the C structures that are exchanged between the API partners. It does not contain any executable code, and the abstract definitions therein are designed to be as flexible and interoperable as possible to support a large variety of <a class="el" href="ara_design_overview.html#sec_LanguageAndPlatformSupport">architectures, languages and compilers</a>. <br>                              </p>
<p>The accompanying <code>ARADebug.h</code> helpers provided with the SDK are compatible with this lowest C layer; they only add minimal standard C and OS dependencies and ease implementing <a class="el" href="group___debugging.html">ARA assertions</a>. <br>                              </p>
<p>The mini host example is written in C using the raw API and the ARADebug utilities. <br>                              </p>
<p>If you're not using C++, or are stuck with a very old C++ compiler, then this layer is your only choice. Otherwise, there should be only very few reasons to stick to this lowest level. <br>                              </p>
<h2><a class="anchor" id="autotoc_md13"></a>
C++ Dispatcher, Utilities</h2>
<p>The C++ dispatch level defines minimal abstract classes and helper templates for both hosts and plug-ins that encapsulate the underlying C ARA interface. It does not provide any validation or other functional code beyond forwarding the C API calls into the C++ world. Compared to ARAInterface, it merely adds dependencies to a few C++11 standard headers. <br>                              </p>
<p>As an optional addition to the basic dispatching, <a class="el" href="group___a_r_a___library___utilities.html">`Utilities`</a> provide various useful helpers designed to work in tandem with the dispatcher-based code. <br>                               The <code>Debug</code> folder also contains additional code for debugging when using these classes. <br>                              </p>
<p>The dispatch level is typically used by host vendors, since the host code structures differ widely so that higher abstractions hardly apply. <br>                               The ARA test host makes use of the host dispatch classes as well. <br>                              </p>
<p>For plug-in developers, starting at this layer may be convenient if the code base already contains C++ classes representing ARA objects, or if they find that the higher ARAPlug level has more abstraction than necessary or applicable. <br>                              </p>
<h2><a class="anchor" id="autotoc_md14"></a>
ARAPlug</h2>
<p>The ARAPlug layer provides a whole suite of C++ classes that represent every component of the ARA model graph, along with its document controller and representations of the ARA plug-in instance roles. It also provides many convenience classes and utility functions that simplify various tasks like archiving, content reading or sending update notifications to the host. <br>                              </p>
<p>It is the highest in terms of abstraction and convenience and is used to for the ARA test plug-in included with the SDK. We recommend that new ARA plug-in developers start with this layer. <br>                               Please see the <a class="el" href="group___a_r_a___library___a_r_a_plug.html">ARAPlug</a> documentation for more information. <br>                              </p>
<h2><a class="anchor" id="autotoc_md15"></a>
JUCE_ARA</h2>
<p><a href="https://juce.com">JUCE</a> is a popular framework for audio plug-in development that is seeing wide-spread adoption in the audio developer community. Because our goal is to make ARA development as easy and robust as possible, we've created an experimental <a href="https://github.com/Celemony/JUCE_ARA">JUCE_ARA fork</a> that drafts support for building ARA-enabled plug-ins with JUCE, including an extensive <a href="https://github.com/Celemony/JUCE_ARA/tree/develop/examples/Plugins/ARAPluginDemo">JUCE_ARA plug-in demo</a>. <br>                               Note that Celemony is not endorsing the use of JUCE by providing this fork. JUCE_ARA is a fairly thin adapter to integrate ARA into JUCE, it does not provide any features that would be relevant when using ARA with a different framework. Consequently, the decision whether or not to use JUCE for any given project should be made independently of JUCE_ARA. <br>                              </p>
<h1><a class="anchor" id="autotoc_md16"></a>
Mapping the Internal Model to ARA</h1>
<p>The ARA model defines abstractions that allow for mapping a wide range of host and plug-in models to it. In several cases though, the mapping may not be entirely straight forward - there will likely be some "impedance mismatches". <br>                               The general guideline here should be for the host to configure and for the plug-in to interpret the ARA model not driven by their actual internal data model, but rather by the user representation thereof. This ensures that from a user's perspective, host and plug-in feel "in sync" as tightly as possible. <br>                              </p>
<h2><a class="anchor" id="autotoc_md17"></a>
Dealing with overlapping Playback Regions</h2>
<p>An example for this approach is dealing with region overlaps. Hosts typically define a z-order between regions, and depending on the host implementation and potentially user preferences, overlapping regions will sound concurrently, or only the top-most region will be audible in the overlap range (possibly using a cross fade range at the border where both the obscured and the top-most region are playing). <br>                               In the latter case, when configuring the ARA playback regions the host should restrict the borders of the partially covered region(s) to those areas that are not fully obscured by other regions and thus actually do sound when playing back. Note that depending on the position and duration of the overlap(s), this may include slicing one partially covered region in the host into two or more regions at ARA API level. This way, the plug-in will only display and render audio material that is actually audible in the host. <br>                              </p>
<h2><a class="anchor" id="autotoc_md18"></a>
What should Audio Modifications represent in a host?</h2>
<p>Another area that tends to be no straight match is that hosts often either lack a dedicated audio modification abstraction, or use a somewhat different separation between playback region and audio modification. <br>                               If the modification abstraction is not part of the host model, then the typical approach is to use a fixed 1:1 relationship between audio source and audio modification, which results in any modification edit to be reflected in all playback regions that cover the edited modification range - the regions are "aliases", not distinct copies. <br>                              </p>
<p>If the host model includes some concept of multiple modifications per audio file, there must be some logic implemented to decide whether a newly created region shall be using an existing modification, or whether a new modification should be created. In the latter case, there's the option to clone an existing modification or create a new one from the original audio source state. <br>                               To come up with a proper pattern to address those concerns in a given host, it is often valuable to compare this to the MIDI capabilities of the host as reference. A typical pattern is to create aliases per default, but provide an option to turn an alias into a distinct copy (modifier upon creation, or conversion command). <br>                               An alternate approach is to conceptually treat every region as an independent copy. In that case, the relationship between playback regions and modifications is 1:1. This pattern is especially viable if ARA's separation between modification and region does not map well to the host model. <br>                              </p>
<p>Another consideration to keep in mind is that compared to plain audio files, ARA audio modifications are not limited in the time range they cover. Users can freely copy or move the original material around, this extends beyond start and end of the underlying audio source. <br>                               It is therefore desirable to allow ARA users to extend the playback region borders beyond the range of the audio source, instead of applying the typical border restriction implemented for regular audio files. Depending on whether this restriction is implemented at control layer or in the model, it needs to be considered either when mapping the model or when adjusting the user interface for ARA, see below. <br>                              </p>
<h2><a class="anchor" id="autotoc_md19"></a>
What do Region Sequences represent?</h2>
<p>Region sequences typically map to arrangement tracks or lanes, but as with the other mapping topics discussed above this may not always be a direct match. For example, some hosts allow for storing several alternate versions of the arrangement per lane, and let the user pick one version that is currently editable and played back. <br>                               In order for each track version to preserve its distinct ARA edit state, hosts must use separate audio modifications per version (while still sharing the underlying audio sources). When duplicating versions, the affected audio modifications will be cloned. <br>                               In order to prevent inactive versions from cluttering the plug-in UI, hosts should only expose a single region sequence per versioned track, containing only the current version's playback regions. If the active version is switched, the region sequences remain as-is, but all the playback regions are replaced as needed. <br>                              </p>
<p>A similar pattern applies when comping: there should be a single region sequence representing the resulting comp lane, holding playback regions based on the selection made on the per-take lanes. This may be different from some host implementations where the resulting comp is merely a UI entity, and the internal engine just plays the selected regions from the take lanes. <br>                              </p>
<h1><a class="anchor" id="autotoc_md20"></a>
Configuring the rendering</h1>
<h2><a class="anchor" id="autotoc_md21"></a>
Setting up an ARA Playback Renderer</h2>
<p>The setup process for an ARA-enabled plug-in instance is not much different from setting up a non-ARA plug-in instance, but there's some considerations worth mentioning, mostly related to the fact that the audio source replaces the realtime input of the plug-in. <br>                              </p>
<p>The established plug-in APIs usually define two states for a plug-in: a setup state, where certain configurations such as the maximum render block size may be changed, but no rendering may occur, and a render state where the configuration is fixed but rendering may occur. <br>                               In most APIs, changing the I/O configuration is restricted to the setup state. Assigning playback regions to an ARA playback renderer plug-in instance can be considered an I/O change too, and thus is always restricted to the setup state. (Note that this is different for editor renderers, see below.) <br>                              </p>
<p>Since ARA playback renderers have no realtime inputs, it would seem appropriate to suppress these in the supported I/O configurations published through the underlying companion APIs. However, given that preview renderers do use their inputs, and that a plug-in instance can be both playback and editor renderer, the I/O configurations made available by the plug-in must not depend upon ARA being enabled or not or on the assigned ARA instance roles. <br>                               Instead, for plug-in instances that do only playback but no editor rendering, ARA establishes the rule that the main inputs are simply never used - plug-ins never read them, and hosts do not need to supply a meaningful signal. <br>                              </p>
<p>Ignoring the realtime inputs also means that ARA playback renderers should not incur any processing latency, because it can be completely compensated for inside the plug-in. Plug-ins must make sure to report this correctly through the companion API, and hosts should read the latency only after establishing the ARA binding. <br>                              </p>
<p>Further, being independent of realtime input means that ARA playback renderers can be processed ahead of the actual playback location using rather large buffers to reduce CPU load, because the larger latency introduced by this can be fully compensated for. Note that this also includes proper visual latency compensation as supported by <code>VST3</code>'s <code>IAudioPresentationLatency</code> or by <code>Audio Units</code>'s <br>                               <code>kAudioUnitProperty_PresentationLatency</code>. <br>                              </p>
<p>Using larger buffers is particularly useful when a plug-in internally applies some sort of transformation into the frequency domain, because it then needs to apply internal buffering for the transformation and will cause high spikes of CPU load in all render slices where it can process a full transformation buffer, but will hardly do any work in all other render slices. Using render slice sizes that are about as large as the plug-in's internal transformation buffer therefore leads to a much steadier overall CPU load. <br>                               It is therefore highly recommended to process ARA-enabled playback with render slice sizes between 1024 and 4096 samples because these sizes are typically used internally in frequency domain related DSP algorithms. <br>                              </p>
<p>Following these considerations, a host might even decide to render ARA playback renderers inside its file I/O thread (much like a realtime MP3 decoder), instead of performing the rendering from the realtime audio processing thread. Doing this is certainly valid and only requires to properly flag non-realtime usage to the plug-in, using <code>VST</code>'s <code>kVstProcessLevelOffline</code> or <code>Audio Units</code>'s <br>                               <code>kAudioUnitProperty_OfflineRender</code> etc. <br>                              </p>
<h2><a class="anchor" id="autotoc_md22"></a>
Preview Rendering</h2>
<p>In addition to the actual audio output signals, ARA allows for temporary, auxilliary signals to be produced while editing the data. These signals are audible clues when performing the model edits, aiding and speeding up the editing process. They typically are only generated when song playback is stopped, in order not to corrupt potential bounces. A prominent example is Melodyne playing back a note when it is grabbed with the mouse and dragged up and down, so its new pitch is immediately audible. Another of these preview features is that it allows for optionally playing back a chord when the user selects it in its chord track. It also features a metronome in its audio source tempo definition editor. <br>                               These three examples show that there generally are two classes of these signals: sounds that are associated with a given playback region or region sequence, which should accordingly be routed through the same effect chain as used during playback of that region or sequence respectively, and song-global sounds that are not associated with a particular mixer channel, such as the aforementioned chord track preview or metronome. Some hosts, most prominently Cubase, feature an explicit monitoring channel for such signals with separate routing capabilities. <br>                              </p>
<p>ARA 2.0 defines a dedicated editor renderer role that enables the host to set up these scenarios as supported: preview renderers can be set up with a set of playback regions or region sequences defined by the host. For a song-global preview renderer, that set remains empty. Hosts shall set up the preview so that it is unambigous, i.e. all the sets should be fully disjoint, and only one set should be empty (song-global renderer). <br>                               Due to their very different nature, editor renderers comply to a different set of rules compared to playback renderers. In terms of signal flow, preview renderers add their signal to any input signal that the host may provide - or if a given plug-in instance is both playback and editor renderer at the same time, to the playback renderer output. <br>                               Since any preview signal is only temporary, drop-outs are acceptable if it eases the implementation. Further, generating the signal is a task in the plug-in that is fully transparent to the host. Therefore, the responsibility to properly react to any ARA model graph edits or signal routing changes (expressed by modifying the set of playback regions or region sequences of a given editor renderer) in a thread-safe fashion is entirely placed on the plug-in - the host can make any of such changes without toggling the plug-in temporarily from render state to setup state, as would be required for playback renderers. An easy way to deal with that requirement on the plug-in side is to simply cease and later resume any preview rendering whenever such a change to the model or the routing occurs. <br>                              </p>
<h2><a class="anchor" id="autotoc_md23"></a>
Sample rate conversion upon playback</h2>
<p>When working with audio material recorded at sample rates different from the current playback setup, sample rate conversion (SRC) algorithms must be applied when rendering the audio. Some hosts deal with this issue by converting all audio files to the playback sample rate upon importing them into a project, but others keep the audio files at their original sample and perform on-the-fly SRC during playback. <br>                               Per default, these hosts should provide the audio source data at the original sample rate to any ARA plug-in in the model graph. This minimizes any artifacts that the SRC introduces, ensuring plug-ins will have the highest quality signal available for analysis and therefore yield the best results. It also prevents potential re-analysis and the according potential loss of edit data when the playback sample rate is changed. <br>                              </p>
<p>Plug-ins must therefore implement an appropriate handling audio sources with different sample rates. Some plug-ins such as Melodyne are capable of integrating the SRC into their DSP algorithms, thereby reducing the overall artifacts. On the other end of the spectrum, some plug-ins may not implement SRC at all, instead choosing to render silence in case of a sample rate mismatch and informing the user that any SRC must be explicitly applied in the host. Note that the host does not know or need to care about the plug-ins SRC implementation, it will always present the situation "as is" and rely on the plug-in to deal with it appropriately. <br>                              </p>
<p>If the plug-in does implement SRC, users should be aware that non-ARA audio sources or audio sources processed by different ARA plug-ins will be converted using different algorithms. This can result in differing levels of quality, or even changes in phase in extreme cases, which is problematic in applications where phase alignment is crucial. <br>                               In such cases, it is up to the plug-in vendor to educate users about the issue.For example, the plug-in could detect whether SRC is required, and instruct the user to either add the plug-in to all phase-aligned recordings to achieve consistent conversion, or to explicitly convert them all in the host before proceeding, whatever yields the preferred results. <br>                              </p>
<h2><a class="anchor" id="autotoc_md24"></a>
Playback region head and tail times</h2>
<p>Companion APIs allow plug-ins to publish a "tail time" that informs hosts of a signal that will be appended beyond the end of the input signal. ARA adopts this concept for each region. Since ARA is a random access API, it also extends this to include a matching head time before the start of the region. <br>                               When rendering playback regions, host must take the head and tail time into account to allow the playback renderers to generate proper output. Both head and tail time default to 0. The plug-in can signal changes through playback region content update notifications. <br>                              </p>
<h2><a class="anchor" id="autotoc_md25"></a>
Dealing with denormals</h2>
<p>When processing audio samples, de-normalized floating point values may cause severe performance penalties. A common way to handle this is to switch off denormals in the CPU, as they are irrelevant for the audible results of the rendering. A plug-in that uses this technique must potentially perform the switch whenever the host calls into the plug-in, and must switch back before exiting. To avoid this considerable overhead, it is recommended that host applications generally turn off denormals, so that plug-ins do not need to perform this switching at the begin and end of each render call. <br>                              </p>
<h2><a class="anchor" id="autotoc_md26"></a>
Caching especially CPU-intense DSP</h2>
<p>In some cases, the processing demand for certain ARA edits may be so expensive that it cannot be rendered in realtime. To still allow for proper realtime playback, the processing results (or some intermediate data) must be cached. <br>                              </p>
<p>If such caches can be created within a reasonable short amount of time, the plug-in can manage this data in a typical cache folder that will keep recently used data around until a certain threshold is exceeded. When loading a project that references data no longer part of the cache, the plug-in will recreate the data during the unarchiving process (for which the host will provide a proper progress bar). This approach is implemented e.g. by Melodyne's polyphonic audio processing. <br>                              </p>
<p>There are however rare cases when calculating the render output is so expensive that it will stall the system for several minutes per affected audio modification. In this scenario, the cached data should preferably be kept alive as long as the project that uses the data is being worked on. This is best achieved by placing the cache inside the host's project folder, i.e. a folder specific to the host document that can be used by plug-ins when storing data. <br>                               Finding this folder can be done using special companion API functions. The specific details of these functions vary depending on the companion API being used, but for example PreSonus provides an <code>IContextInfoProvider</code> extension to VST3 that can be downloaded here: <br>                               <a href="https://presonussoftware.com/en_US/developer">www.presonussoftware.com</a></p>
<h1><a class="anchor" id="autotoc_md27"></a>
Analyzing audio material</h1>
<h2><a class="anchor" id="autotoc_md28"></a>
What can be analyzed</h2>
<p>ARA plug-ins typically need some initial analysis phase to build an internal model of the content of a given audio source before users can edit the DSP accordingly. If parts of the model can be mapped to the ARA content types, then the plug-in may export the analyzed data to the host, allowing it to be used as analysis engine - the <code><a class="el" href="group___plug-_in___factory.html#struct_a_r_a_factory" title="Static plug-in factory. All pointers herein must remain valid as long as the binary is loaded....">ARAFactory</a></code> publishes a list of content types that can be provided through analysis. <br>                              </p>
<p>Note that any analysis performed by the plug-in may fail to provide meaningful results for a specific audio source and a given content type, e.g. if the signal is very noisy, or if it does not contain any information of that type. In this case, a plug-in may indicate that no content reading is possible, or it may fall back to some default state and keep providing "initial grade" content despite an analysis was performed - the host must deal properly with both cases. <br>                              </p>
<h2><a class="anchor" id="autotoc_md29"></a>
Manual adjustments</h2>
<p>Some plug-ins such as Melodyne allow for manual adjustments of the analysis results in their UI. When such edits happen, the host will be notified and content grade will be updated accordingly (see below). <br>                              </p>
<p>In addition to the analyzable content, a plug-in may provide means for the user to define more content information for the audio source in its UI (e.g. specifying a key signature). While not determined through analysis and therefore not listed in the <code><a class="el" href="group___plug-_in___factory.html#struct_a_r_a_factory" title="Static plug-in factory. All pointers herein must remain valid as long as the binary is loaded....">ARAFactory</a></code>, such data will still be communicated to the host after the user has edited it, and the host can sync accordingly - listening to all relevant content changes should therefore be done regardless of a given plug-in's analysis capabilities. <br>                              </p>
<h2><a class="anchor" id="autotoc_md30"></a>
Triggering explicit analysis</h2>
<p>Depending on the design of the plug-in, the analysis of a given content type may be started automatically by the plug-in when creating an audio source, or it may be postponed until the user explicitly triggers it on demand throughout its UI. In cases where a host wants to use the analysis capabilities of a plug-in without user interaction, it must therefore explicitly request an analysis. (Host developers can test both behaviours with the ARA Test Plug-In, see the <code>ARA_ALWAYS_PERFORM_ANALYSIS</code> define in <code>ARATestDocumentController.cpp</code>.) <br>                              </p>
<p>If user interaction in the host is blocked while the analysis is running, progress information should be provided by the user - plug-ins must support this if their analysis is taking a non-trivial amount of time. <br>                              </p>
<p>In addition to progress information, a call is available to determine whether or not the analysis for a given content type is still in progress. This call is particularly relevant if the user can perform edits in the plug-in UI while the host waits for the analysis results - it may be possible for the user to restart the analysis with different settings there. <br>                              </p>
<h2><a class="anchor" id="autotoc_md31"></a>
Algorithm selection</h2>
<p>Plug-ins often provide sets of pre-configured analysis and other processing parameters configured for specific materials, such as distinguishing between percussive material versus tonal sounds with clearly perceived pitches. ARA 2.0 allows for exporting these of algorithms to the host so it can configure this appropriately when adding a new audio source - either through UI or through context, such as when recording a new take of a piece of music that has already been analysed before. <br>                              </p>
<h1><a class="anchor" id="autotoc_md32"></a>
Utilizing content exchange</h1>
<p>Content information exchange is a key component of the relationship between ARA host and plug-in, and properly utilizing this information can yield powerful results. Content information resulting from plug-in analysis can be used by the host to adjust project settings to match the content, and plug-ins can use information provided by the host to adjust their transformation accordingly. Also, any information readily available in the host does not need to be analyzed by the plug-in. <br>                              </p>
<p>Content information shared between plug-in and host will be flagged with a "content grade" to indicate it's quality. It will be evaluated when deciding about how to use the information received from the API partner, as illustrated in the examples below. <br>                              </p>
<p>When implementing content readers, it is important to be aware of potential rounding issues when converting between internal data structures and the continuous time used in the ARA API - both when calculating time stamps and when evaluating the optional content time range. <br>                              </p>
<h2><a class="anchor" id="autotoc_md33"></a>
Musical Timing Information, including Content Grade examples</h2>
<p>A proper description of the musical timing (tempo and bar signatures) and how it changes over time is the foundation of many musical applications, ranging from using it as a natural editing grid to applying quantization or aligning some recording to fit some different piece of music. <br>                              </p>
<p>Most hosts define a project-wide musical timing to which the entire arrangement is aligned to. They typically provide a sophisticated UI to edit this timing. In ARA, this timing is modeled as part of the musical context, and plug-ins can read it from the host. <br>                              </p>
<p>In order to align any audio signal properly in this arrangement, the musical timing in the underlying audio source must be known to the host. However, depending on where the recording originated, this information is often missing. An ARA plug-in such as Melodyne which is capable of detecting tempo maps and bar signatures can be used in such cases to obtain the missing data. <br>                              </p>
<p>To start that process, the host would first request the analysis of the audio source, then wait until the plug-in acknowledges the success of the analysis. It can then read the content information from the plug-in. At this point, its content grade will be <code>kARAContentGradeDetected</code>, indicating that the data results from automatic detection without any user intervention. This means that the results may not be entirely reliable since the user has not reviewed them yet - applying automatic transformations such as time stretching to make the audio align with the projects musical timing may yield undesirable results. Some host will therefore suppress such automatic adjustments at this early point, yet they may indicate that the relevant information is available for review. <br>                              </p>
<p>Should the user then adjust the timing definition in plug-in's UI, the grade will transition to <code>kARAContentGradeAdjusted</code>, indicating that the user has reviewed and adjusted the analysis results to their liking. The plug-in will notify the host about this change and the host now should consider the data fully valid and use it to its full potential. <br>                              </p>
<p>This user approval is not required to be done on the plug-in side: if the host features some user interface for editing the audio source tempo information, it can be done there as well and will in turn be communicated to the plug-in, exactly mirroring the case described above. <br>                              </p>
<p>This symmetry in using content readers also extends to hosts that feature built-in tempo detection - when the plug-in queries the timing of a given audio source, the host can return a data of with the detected grade. The plug-in can then decide whether this information is plausible or whether it should try to re-detect the tempo. If however the tempo was available in the host because the user entered it, the grade would be adjusted and and the plug-in would accept this and skip its built-in detection. <br>                              </p>
<p>Once host and plug-in agree on the musical timing, the plug-in can be instructed to apply time stretching when rendering playback regions as detailed in the next section <a class="el" href="implementing_a_r_a.html#sec_manipulatingTiming">Manipulating the timing</a>. The host can further implement other features based on this information, such as allowing to set the project time line to match the tempo of an audio source etc. <br>                              </p>
<p>There are two more content grades defined in the ARA API. First, if a content reader is requested before the initial analysis has completed, or if an analysis failed to provide meaningful results, the content information will receive a grade of <code>kARAContentGradeInitial</code> to indicate that the data is not actually related to the content but merely represents some reasonable default value (e.g. a tempo of 120 BPM). <br>                              </p>
<p>Finally, there are scenarios where the audio sources have been carefully preprocessed by some producer, as is the case with some pre-packaged content libraries. Here the content information can be assumed to be fully correct and not to be changed by the user, which is represented by the <code>kARAContentGradeApproved</code>. <br>                              </p>
<p>The content grades apply universally to all content types described in the ARA API, not just to musical timing information. The musical timing content types however are the most widely supported types on both sides of the API and thus serve best as examples illustrating how their content grade affects the actual user workflow on both the host and the plug-in side. <br>                              </p>
<h2><a class="anchor" id="autotoc_md34"></a>
Notes, including examples of transformations affecting content data</h2>
<p>Another example of utilizing content information is performing an "Audio to MIDI" conversion. This is done by using notes detected by the plug-ins analysis to create a new MIDI clip in the host, representing the notes being played in the original audio source. This content type is referred to in code as <code><a class="el" href="group___model___notes.html#struct_a_r_a_content_note" title="Content reader event class: notes provided by kARAContentTypeNotes. Event sort order is by startPosit...">ARAContentNote</a></code>. Like in the previous example, this content information will be given a grade depending on whether any notes were actually detected or what kind of adjustments the user has made on their own. <br>                              </p>
<p>Note content serves well for illustrating the effects of the transformations applied by the plug-in at the different parts of the ARA model graph. At audio source level, the returned notes would describe what was played in the original recording. If the application needs access to this original data, it is available here. <br>                              </p>
<p>When reading at audio modification level, the data would be still in the original timing context, but include all edits that the user has made when rearranging the audio data inside the plug-in. This may be the least valuable information, since these user edits where made within the playback context, and may not be meaningful when being used in the original audio source context. <br>                              </p>
<p>Reading per playback region yields the notes as rendered when playing back the arrangement, so if MIDI export is for example implemented by dragging audio regions in the host to MIDI tracks, this level of content reading must be used. Further, some hosts optionally draw MIDI-like representations of this content information on top of any audio region that is being associated with an ARA plug-in that delivers note content information. <br>                              </p>
<h2><a class="anchor" id="autotoc_md35"></a>
Chords, Key Signatures and other content types</h2>
<p>The third important group of content types is the related to the "chord progression" of the content in musical timing, and the overall key the chords are sounding in, available through <code>kARAContentTypeSheetChords</code> and <code>kARAContentTypeKeySignatures</code> respectively. If the host provides this information in its musical context, it can be used by plug-ins to adjust their pitch editing according to the harmonic structure of the song. This powerful feature can be seen when using Melodyne in Studio One - notes detected by Melodyne can be pitched so that they follow the key scale and/or the chord progression of the song, allowing Studio One's chord track to affect the audio transformations in Melodyne. <br>                              </p>
<p>There are several more content types available that are no discussed in detail here, for example related to tuning/intonation. More content types are likely to be added as the ARA API evolves. See <code>ARAInterface.h</code> for a complete list and detailed description of each type. <br>                              </p>
<h1><a class="anchor" id="sec_manipulatingTiming"></a>
Manipulating the timing</h1>
<p>A key benefit of ARA compared to established plug-in APIs is that musical timing information is provided both on audio source or audio modification level and for the entire playback timeline. If supported by both the host and the plug-in, this allows for several interesting usage scenarios where the timing progresses differently in both domains. <br>                              </p>
<p>The most simple use case is to use ARA as a classic time-stretch algorithm by simply providing a stretch factor for a playback region and ignoring the musical synchronization capabilities, which would be a typical behavior for plain sample editors that do not use musical representation at all. <br>                              </p>
<p>Hosts that deal with musical timing information however can behave much smarter. When they record audio, they should also record the musical timing that was set up during the recording and provide this information at audio source level to ARA-enabled plug-ins. The same applies for any pre-produced content that ships with the host or is available through another provider. <br>                               The plug-ins can use this information to set up their timeline accordingly, resulting in a perfect musical sync when (re-)positioning the playback region or editing the tempo track. <br>                              </p>
<p>Most hosts also allow for importing audio files that were recorded without proper timing information embedded into the file. In that case, the host should rely on the tempo analysis of the ARA plug-in. This will detect both the tempo and the location of the beats in relation to the start of the audio source. <br>                               Using this information, the host can adjust the placement and stretching of the imported audio so that it perfectly fits the song. Note that this means that the proper location of the audio is not known until the analysis is finished - either the import must be delayed for that time or the host must update the location after the results of the analysis are available. <br>                              </p>
<p>ARA plug-ins may also allow for reinterpreting the tempo, such as applying half-time feeling. Also, imported audio may be tagged with wrong timing information so users may need to override the timing provided for an audio source. Hosts should therefore listen to the according content change notification from the plug-in and re-adjust stretching and placement if desired. <br>                              </p>
<p>Whenever the musical timing in the audio doesn't fit the song, there's various options to deal with the situation. <br>                               In rare cases, this should not be resolved at all, and the material should not be manipulated timing-wise (but it may still be altered pitch-wise). The host would then set up the playback region so that the duration in source and target times are equal and adjustments to the playback tempo are disabled. <br>                               In other cases, the user may prefer to adjust the song's timeline to match the material. This would be implemented as a dedicated feature in the host by using the timing information provided by the plug-in and updating the song timeline, then using a non-timing-altering ARA playback region as discussed in the previous case. <br>                              </p>
<p>In the most likely case however it is desired that the ARA plug-in modifies the audio material according to the song. Consider the following example (each line represents a beat drawn in time-linear): </p><pre class="fragment">song timing:     |      |      |      |      | (constant tempo)
detected timing: |     |     |   |   |         (tempo is faster in the second half)
</pre><p>Here it is necessary to stretch the original to fit the song. <br>                              </p>
<p>There are two ways to do that: either stretching linearly so that everything is made faster or slower by the same amount, or use the relationship between both timelines so that each tempo-section is stretched differently to achieve a perfect match: </p><pre class="fragment">song timing:     |      |      |      |      | (constant tempo)
equal stretch:   |       |       |     |     | (still faster in the second half, by same ratio)
tempo-adjusted:  |      |      |      |      | (constant tempo)
</pre><p>While the latter case is much more common, the first has its uses too, so the host should ideally enable the user to choose between both. <br>                               Note that the above examples are simplified, real-world calculations cannot assume constant tempo for either timeline and also need to properly reflect potential offsets between the first beat of the song/the audio source and the start of the song/the audio source. <br>                              </p>
<p>Note that when mapping beats, the plug-in may choose to apply any algorithm suitable. It may even offer the user an option to choose some sort of groove pattern that is to be taken into account when calculating the mapping. If a plug-in offers such an option, it must do so at audio modification level. <br>                              </p>
<h1><a class="anchor" id="autotoc_md36"></a>
Content Based Fades</h1>
<p>The head and tail time of playback regions can be leveraged by plug-ins to implement content based fades at the region borders. Instead of fading the overall signal, plug-ins can re-interpret these border fades depending on the type of content that will be playing when the fade occurs. This is best explained with an example: <br>                              </p>
<p> <object data="ARA2HowTo_ContentBasedFade.pdf#toolbar=0&navpanes=0&scrollbar=0" width=" 591px" height=" 500px">                                        </object>                                        </p>
<p>This shows a region being sliced at a time that causes notes to be cut off or start after their transient. Instead of applying a traditional overall fade-out/fade-in, the plug-in could reflect this in its playback model so that each note that intersects with the transition is either completely played in the tail of the first or the head of the second region, so no fades are necessary at all. <br>                               This concept could be extended further - the plug-in could actually modify the notes that are intersected by the borders so that they start / stop as close as possible to the region boundaries, further improving the quality of the fade in a way that a traditional crossfade could not do. Head and tail time should always be kept at the minimum time that is required for achieving such a natural sounding processing of the region borders. <br>                               Content-based fades can be particularly strong when comping. Picking notes from either the first or the second region allows to deal with situations where overall fades are bound to create artefacts, such as when the notes in the second region are played slightly later than in the first. <br>                               The actual implementation of content based fades is entirely dependent on the internal processing algorithms of the plug-in. If those algorithms do not naturally provide an alternative to traditional overall fades, the plug-in should not implement this feature, and the host will then just use existing fade-based implementation used also for non-ARA regions.</p>
<h1><a class="anchor" id="sec_ManagingARAArchives"></a>
Managing ARA Archives</h1>
<p>An important aspect to consider when implementing persistency is dealing properly with the various persistent IDs in the ARA API and their associated versioning. There are three IDs involved: the <code><a class="el" href="group___plug-_in___factory.html#a8b4674d522a7a9ac4268db43b614437c" title="Unique and versioned plug-in identifier. This ID must be globally unique and identifies the plug-in&#39;s...">ARAFactory::factoryID</a></code>, the <code><a class="el" href="group___plug-_in___factory.html#adebff6774723eb0490324afdcb2a993d" title="Identifier for document archives created by the document controller. This ID must be globally unique ...">ARAFactory::documentArchiveID</a></code> and the plug-in ID as defined via the companion API. <br>                              </p>
<p>The <code>factoryID</code> serves a runtime ID of the plug-in - it can be used to uniquely identify a specific version of a specific ARA plug-in, for example when copy/pasting plug-in state between documents. It also enables the host to determine whether the same ARA plug-in is installed across different companion APIs, such as an Audio Unit and VST3 version of the same plug-in. This allows to filter duplicate plug-ins and choose only a single companion API for each ARA plug-in as detailled later in Choosing Companion APIs. <br>                               As long as the<code>factoryID</code> has not changed, the host-observable ARA behavior of the plug-in has not changed - e.g. it has the same analysis capabilities, supports the same archives etc. Hosts can therefore choose to store such information about the plug-in in a cache to avoid fully loading all plug-ins at each application startup, and update this cache whenever the <code>factoryID</code> changes. <br>                              </p>
<p>The <code>documentArchiveID</code> uniquely identifies opaque archives of ARA plug-in state and must be stored by the host alongside the raw archive bytes whenever calling <code><a class="el" href="group___plug-_in___document___controller.html#ace1b9e50ef7c1da581304e5808de6c87" title="Create a partial archive of the internal state of the specified objects. Archives may only be created...">ARADocumentControllerInterface::storeObjectsToArchive()</a></code> (or the legacy <code><a class="el" href="group___plug-_in___document___controller.html#add26a04ae54ea3fdde8952f1cb9e05b9" title="Create an archive of the internal state of a given document and all its associated objects....">ARADocumentControllerInterface::storeDocumentToArchive()</a></code>). The host should also store the user-readable meta information about the plug-in (<code><a class="el" href="group___plug-_in___factory.html#a341b269750f1c71e37d9717a6c04cd46" title="Name of the plug-in to display to the user.">ARAFactory::plugInName</a></code>, <code><a class="el" href="group___plug-_in___factory.html#a4eba81b15dddeb2d342a2a8bf57a8113" title="Name of the manufacturer of the plug-in to display to the user.">ARAFactory::manufacturerName</a></code>, <code><a class="el" href="group___plug-_in___factory.html#ae4328146f1b55f9bc7d0e694e1bb6b16" title="Web page to refer the user to if they need further information about the plug-in.">ARAFactory::informationURL</a></code> and <code><a class="el" href="group___plug-_in___factory.html#a4c00e0226ef2e553d8c614304891485d" title="Version string of the plug-in to display to the user.">ARAFactory::version</a></code>) so it can later provide a proper error dialog should the archive be loaded on a system where the plug-in is missing or outdated, informing the user which version of which plug-in is needed and where to get it. <br>                              </p>
<p>If a plug-in is updated in a way that makes its archived state incompatible with previous versions, both the <code>factoryID</code> and the <code>documentArchiveID</code> must be adjusted. Further, the previous <code>documentArchiveID</code> must be added to the list of <code><a class="el" href="group___plug-_in___factory.html#ad086f2eb62f7a90a0ea6fa22f5ea6f78" title="Variable-sized C array listing other identifiers of archives that the document controller can import....">ARAFactory::compatibleDocumentArchiveIDs</a></code> and proper import code must be written to read existing archives in that previous format. <br>                               If the new version of the plug-in is installed, the host can detect that change via the udated <code>factoryID</code>. It will then read the new <code><a class="el" href="group___plug-_in___factory.html#struct_a_r_a_factory" title="Static plug-in factory. All pointers herein must remain valid as long as the binary is loaded....">ARAFactory</a></code> data and recognize the new <code>documentArchiveID</code> and the updated list of <code>compatibleDocumentArchiveIDs</code>. If a project is loaded that contains an old archive, the host will find the old ID in the list of compatible IDs and therefore knows that the plug-in will safely migrate the data. <br>                              </p>
<p>A <code>documentArchiveID</code> is not necessarily unique to a specific plug-in. It is valid for any plug-in to be able to read or write archives that can also be processed by another plug-in. This allows for migration paths between different plug-ins, not just between updates of the same plug-in. It however also implies that the archive ID is not suitable to identify a given ARA plug-in - instead, the companion API provides proper IDs to handle that task. <br>                              </p>
<p>To sum things up, let's step through the project load sequence from a host's perspective. The project archive typically contains a list of archived ARA document states, including the associated meta information from the <code><a class="el" href="group___plug-_in___factory.html#struct_a_r_a_factory" title="Static plug-in factory. All pointers herein must remain valid as long as the binary is loaded....">ARAFactory</a></code> described above as well as the companion API plug-in ID. For each of these states, the host first checks via the companion API whether the plug-in is currently installed in the system. If it is, the host then validates that the installed version can in fact read the archive by comparing its <code>documentArchiveID</code> and <code>compatibleDocumentArchiveIDs</code> with the document archive ID stored in the project. If ID is not listed, the installed plug-in is outdated and the host will show an appropriate error message. <br>                               If no plug-in has been found through the companion API, the host compares the project's document archive ID against the <code>documentArchiveID</code> and <code>compatibleDocumentArchiveIDs</code> of all installed ARA plug-ins. If another plug-in supports reading archives with the given IDs, the host can proceed to migrate the project to the new plug-in by loading the document archive via the new plug-in's document controller, and also switching all insert points in the arrangement that used the previous plug-in to the new one so that they can be bound properly to the migrated document controller. <br>                               With the ARA document controller and its associated document state restored, the host will then create companion API instances to fulfill the various required instance roles and bind them to the document controller. Both <code>kARAPlaybackRendererRole</code> and <code>kARAEditorRendererRole</code> are transient, so no state must be saved or restored for these via the companion API. Instances with the <code>kARAEditorViewRole</code> however may use that state to store customizable view configuration, so their state must be persisted and restored via the companion API. <br>                              </p>
<h1><a class="anchor" id="sec_PartialPersistency"></a>
Partial Persistency</h1>
<p>Partial persistence is a feature added in ARA 2.0 that allows to limit storing or restoring objects to a subset of the current ARA graph by providing an optional filter to the store/restore operation. This can be used to export groups of objects from one document and import them into another. It also enables hosts to split the potentially large archive of a document into smaller chunks, which may be useful in data base or network sync contexts, and is used when processing ARA audio file chunks. <br>                              </p>
<h2><a class="anchor" id="autotoc_md37"></a>
Copying ARA data between documents</h2>
<p>A common use case for filtering the scope of archiving operations is implementing a feature that allows users to copy data between ARA documents, typically via copy/paste commands or drag and drop operations. This requires both an '<a class="el" href="group___partial___document___persistency.html#struct_a_r_a_store_objects_filter" title="Optional filter when storing objects.  &lt;br&gt;                               \newline                   ...">ARAStoreObjectsFilter</a>' to store only the selected objects from the source document, and an <a class="el" href="group___partial___document___persistency.html#struct_a_r_a_restore_objects_filter" title="Optional filter when restoring objects.  &lt;br&gt;                               \newline                 ...">ARARestoreObjectsFilter</a> to initialize the newly created target objects. <br>                              </p>
<p>When performing this operation, it is important that hosts manage the persistent IDs correctly, i.e. make sure that the IDs used in the source document while storing do not collide with IDs used in the target document. If there is a conflict, then hosts must map the stored IDs to new unique IDs, export this mapping to the plug-in in the '<a class="el" href="group___partial___document___persistency.html#struct_a_r_a_restore_objects_filter" title="Optional filter when restoring objects.  &lt;br&gt;                               \newline                 ...">ARARestoreObjectsFilter</a>'. To see the filters in action, study the <code>testDragAndDrop()</code> function in the ARA Test Host. <br>                              </p>
<h2><a class="anchor" id="autotoc_md38"></a>
Audio File Chunks</h2>
<p>Another use case for partial persistence is importing WAV or AIFF files that contain <a class="el" href="group___a_r_a_audio_file_chunks.html">ARA audio file chunks</a>. These chunks allow for embedding the archive of an audio source state into the audio files that contain the audio samples for the source via the the <a href="http://www.ixml.info/">iXML standard</a>. <br>                              </p>
<p>There are currently two main use cases for these chunks. First, for plug-ins which may require extensive analysis or manual editing of the audio source internal model, this is a way for content providers to ship audio content with these tasks already accomplished, so that user can go ahead and use the content with the supported plug-ins immediately without going to these time-consuming processes. <br>                               For example, 3rd party audio samples provider could create a loop library with polyphonic detection data for Melodyne and other plug-ins provided up-front in the iXML chunks, so user can load these loops and directly adjust the loops to their song's harmonies without further preparation. <br>                              </p>
<p>The other major use case are plug-ins which generate audio content, e.g by de-mixing audio material or by exporting audio from one plug-in to another. An example here is SpectraLayers, which allows user to drag layers out of the plug-in into the host. The layer's samples are rendered into a new audio file which is then passed to the host's file drop handler. The host imports the file and parses the iXML chunk to find that it should automatically add SpectraLayers to the playback region created upon file import. <br>                              </p>
<p>Note that in both cases, the audio files are not created by the host but rather by code that is provided by the plug-in developer, either as part of the plug-in or as standalone application. To keep the chunks small and to speed up file loading, plug-in developers may accordingly choose to use a different archive format compared to ARA document archives, as done in Melodyne. <br>                              </p>
<h1><a class="anchor" id="autotoc_md39"></a>
User interface considerations</h1>
<p>For the better part of it, ARA relies on the companion API regarding how to create and use the graphical user interface of a plug-in. There are however a few things to consider in order to support the full ARA experience. <br>                              </p>
<p>In many ways, ARA-enabled regions work similar to MIDI regions. It is often desirable to embed the UI for an ARA plug-in into the main window, similar to the MIDI editors in many hosts, such as Studio One. This is possible without further API changes across all currently supported companion APIs, provided that plug-ins support high DPI content scaling on Windows properly. <br>                               Note that some hosts rely on custom extensions of the companion APIs for view embedding, for example see <a class="el" href="implementing_a_r_a.html#sec_ViewEmbedding">`Presonus::IPlugInViewEmbedding`</a>. <br>                              </p>
<p>Further following the MIDI editor analogy, those editors tend to optionally update the contents of their view based the selection in the arrange area. Since navigation and selection in the arrange area are core workflows that are well understood by all users, relying on them is preferable to implementing a different workflow for the MIDI editor. <br>                               The same considerations hold true for ARA-enabled plug-ins, so the API provides means for the host to communicate the arrangement selection in a way that plug-ins can follow in whatever is a suitable way for their UI. This selection optionally covers regions, tracks and a time range, so that the various arrangement selection techniques in current hosts can be mapped to a proper ARA 2 representation. <br>                               Note that most MIDI editors include the option to "pin" the current view state - ARA plug-ins are expected to implement such a feature too if applicable to their user interface. <br>                              </p>
<p>An area that is often problematic when using plug-in views via the established APIs is the routing of key commands. While ARA doesn't actually need to define anything special here, all developers shall be reminded to check proper routing of all key events to the plug-in depending on whether or not it has keyboard focus. <br>                               In your <code>Cocoa</code> implementation in particular, double-check that you've implemented all methods that handle events properly (most notably <code>-performKeyEquivalent:</code>) and that you're maintaining the first responder properly - see <a href="https://developer.apple.com/library/mac/#documentation/Cocoa/Conceptual/EventOverview/HandlingKeyEvents/HandlingKeyEvents.html#//apple_ref/doc/uid/10000060i-CH7-SW1">Apple's documentation</a> on the topic. <br>                              </p>
<h1><a class="anchor" id="autotoc_md40"></a>
Choosing Companion APIs</h1>
<p>Plug-ins typically will support most/all companion APIs in order to provide the highest compatibility. <br>                              </p>
<p>Hosts however usually choose to support only a single companion API, as doing otherwise requires extra coding efforts to avoid using the same plug-in concurrently through different companion APIs and increases testing efforts without adding features. <br>                              </p>
<h1><a class="anchor" id="sec_vst3Considerations"></a>
VST3 specific considerations</h1>
<h2><a class="anchor" id="autotoc_md41"></a>
setActive vs. setProcessing</h2>
<p>Both hosts and plug-ins should be aware of the difference between <code>IAudioProcessor::setProcessing</code> and <code>IComponent::setActive</code> when dealing with plug-in instances. As per the VST3 documentation, the <code>setProcessing</code> function should be limited to light operations that reset the internal processing state, whereas <code>setActive</code> is used for heavy-weight initialization and memory allocation. <br>                              </p>
<p>Unfortunately, when VST3 was initially established there where some confusions about these calls, which have resulted in some plug-ins not resetting properly upon <code>setProcessing</code>, and some hosts in turn calling <code>setActive</code> instead to work around issues with resetting plug-ins. <br>                              </p>
<p>When adding ARA support, plug-ins are required to properly implement the VST3 specification, and hosts will accordingly rely on ARA plug-ins responding properly to <code>setProcessing</code>. Doing otherwise and sticking with <code>setActive</code> for reset can cause severe performance issues with large songs with several thousand playback regions, because accordingly as many playback renderer instances will be performing their memory allocations and complex initialization upon each reset, e.g. each when starting playback. <br>                              </p>
<h2><a class="anchor" id="sec_ViewEmbedding"></a>
View Embedding</h2>
<p>Continuing with the MIDI editor example above - many hosts display their internal MIDI editors inside a view embedded in the host UI (i.e a piano roll view or step sequence view.) To indicate that this embedding is appropriate for a given plug-in, PreSonus has defined the <code>IPlugInViewEmbedding</code> interface here: <a href="https://presonussoftware.com/en_US/developer">www.presonussoftware.com</a>. Implementing this interface will allow your plug-in's UI to be embedded into the UI of hosts supporting the extension (i.e Studio One and SONAR.) <br>                              </p>
<p>Implementing this interface is simple - to see the embedded view in action, check out the <a href="https://github.com/Celemony/JUCE_ARA/tree/develop/examples/Plugins/ARAPluginDemo">JUCE_ARA plug-in demo</a>. <br>                              </p>
<p>Note that other hosts may not require a certain interface in order to enable view embedding, or define other custom interfaces for this. <br>                              </p>
<h2><a class="anchor" id="autotoc_md42"></a>
View Scaling</h2>
<p>To allow proper scaling of the plug-in's UI in host windows, ARA 2 plug-ins must support the VST3 code{IPlugViewContentScaleSupport} interface. Otherwise view scaling mismatches will prohibit embedding the plug-in view properly as discussed above. <br>                              </p>
<h1><a class="anchor" id="autotoc_md43"></a>
Audio Unit specific considerations</h1>
<h2><a class="anchor" id="autotoc_md44"></a>
Buffer allocation</h2>
<p>The Audio Unit API uses a very complex I/O setup scenario with various connection options. While plug-ins must be prepared to handle all these options, hosts typically only use a specific one for all Audio Units. To allow optimization for the concrete connection in use, the Audio Unit specification includes the property <code>kAudioUnitProperty_ShouldAllocateBuffer</code> for both inputs and outputs. <br>                               Since ARA implementations typically rely on a high number of plug-in instances (typically one playback renderer instance per playback region, plus editor rendering instances), it is important that hosts enable this optimization by configuring the ARA Audio Unit instances accordingly. <br>                               Plug-in implementations must evaluate the property accordingly, which will happen automatically if the implementation is based on the Core Audio Utility Classes (like done in the SDK test plug-in), but may require extra coding otherwise. <br>                              </p>
<h1><a class="anchor" id="autotoc_md45"></a>
Future ARA development</h1>
<p>There are several features that have been discussed when developing the API in its current form which were postponed for the time being because defining and implementing them properly needs more input from a wider range of development partners. The goal was to avoid designing API that would not actually be used, or would not work as desired in the various use cases that potential ARA development partners would come up with. As both hosts and plug-ins evolve and more and more developers are adopting the ARA standard, these features may shape up and eventually become part of the next generation of ARA: <br>                              </p>
<ul>
<li>undo/redo integration with the host</li>
<li>support for instrument plug-ins (i.e. no audio sources)</li>
<li>support for MIDI plug-ins</li>
<li>improved support for "warp-"/"bend-"markers as found in many hosts</li>
<li>support for phase-locked editing across concurrently recorded audio sources</li>
<li>support for comping/takes</li>
<li>running the analysis while recording the audio</li>
<li>improved support for multi-channel audio sources (spacial layout information)</li>
<li>optional side-chains and realtime input</li>
</ul>
<p>Developer's feedback about how to design these or other missing features is highly welcome. <br>                               </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
