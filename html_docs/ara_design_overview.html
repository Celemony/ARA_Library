<!-- HTML header for doxygen 1.8.15-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ARA SDK 2.2.0: ARA Design Overview</title>
<link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="shortcut icon" sizes="16x16" href="./favicon.ico">
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<link href="DoxygenStyleSheet.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="ARA_Logo.png" height="50px"/></td>
   <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.svg"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('ara_design_overview.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">ARA Design Overview </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#sec_ARATechnicalDesign">Technical Design Overview</a><ul><li class="level2"><a href="#sec_ARACompanionAPIs">Relationship Between ARA And Established Plug-In APIs</a></li>
<li class="level2"><a href="#sec_LanguageAndPlatformSupport">Language And Platform Support</a></li>
<li class="level2"><a href="#autotoc_md1">API Versioning</a></li>
<li class="level2"><a href="#sec_ARA_Object_References">Objects And Object References</a></li>
</ul>
</li>
<li class="level1"><a href="#sec_ARA_Document_Controller">The ARA Document Controller</a></li>
<li class="level1"><a href="#sec_ModelGraphOverview">ARA Model Graph Overview</a></li>
<li class="level1"><a href="#autotoc_md2">Exchanging Content Information</a></li>
<li class="level1"><a href="#autotoc_md3">Updating The ARA Model Graph</a></li>
<li class="level1"><a href="#autotoc_md4">ARA Model Persistency</a></li>
<li class="level1"><a href="#autotoc_md5">Host Signal Flow And Threading</a></li>
<li class="level1"><a href="#autotoc_md6">Inserting ARA Into The Signal Flow</a></li>
<li class="level1"><a href="#sec_PlugInInstanceRoles">Plug-In Instance Roles</a></li>
<li class="level1"><a href="#sec_AudioAccessAndThreading">Audio Access And Threading</a></li>
</ul>
</div>
<div class="textblock"><p></p>
<h1><a class="anchor" id="sec_ARATechnicalDesign"></a>
Technical Design Overview</h1>
<p>The ARA API is designed to be consistent, simple-to-use and very flexible. It tries not to rely on any assumptions about the actual implementation on either side. <br>                               Various parts of the API are optional, allowing both ARA-capable hosts and plug-ins to only support those aspects of ARA that are meaningful within their particular context. Each side should strive to make as much of its functionality available to the other side as possible, but should not make any assumption about how exactly that functionality will actually be used. <br>                               A good example for this pattern is the exchange of analysis results: if asked for it, the plug-in will deliver all data it can possibly derive via its analysis capabilities, but building features like audio-to-MIDI conversion or synchronizing and quantizing live recordings based on the plug-in's analysis is entirely up to the host - it may come up with features that the plug-in's creators never thought of. <br>                              </p>
<h2><a class="anchor" id="sec_ARACompanionAPIs"></a>
Relationship Between ARA And Established Plug-In APIs</h2>
<p>Each implementation of ARA relies on an established plug-in standard that is used as a companion standard to the ARA API. Currently, <a href="https://github.com/steinbergmedia/vst3sdk"><code>VST3</code></a> and <a href="https://developer.apple.com/documentation/audiotoolbox"><code>Audio Units</code></a> are supported. The companion API defines all the usual tasks for audio plug-ins such as discovering and loading plug-in binaries, configuring and executing both realtime and offline rendering, providing a user interface for the plug-in and so on. <br>                               Lightweight extensions to the companion API then provide access to the additional ARA-specific functions for managing the ARA model, providing plug-ins with random access to the audio data, etc. These ARA interfaces are defined generically and are independent of the companion API in use, allowing developers to decouple the bulk of their ARA-related codebase from the particular companion API they are supporting. <br>                               The companion API itself will still be used strictly according to its definitions and rules, ARA does not abuse or re-define its features. <br>                              </p>
<p>The decision to design ARA as such an extension to various established plug-in standards was made to keep the implementation efforts for both hosts and plug-ins adopting ARA as small as possible. It serves this purpose well on the technical side, but it unfortunately also blurs the lines what an ARA-enabled plug-in actually is and how it should be used. <br>                               An ARA-enabled plug-in is not simply an established realtime plug-in with some extra features, but rather a whole new breed of plug-in that has different capabilities and constraints. Both hosts and plug-ins must reflect this distinction in their implementations and conceptually separate an ARA-enabled plug-in from its non-ARA-enabled counterpart: Although they live in the same binary, each version is to be treated as a separate and incompatible plug-in. <br>                              </p>
<p>Hosts can provide both versions next to each other and let the user choose which to insert (e.g. Logic Pro X), or can automatically prefer the ARA-enabled version if the insert point is suitable for ARA (i.e. first in chain) and fall back to the non-ARA version otherwise (e.g. Studio One). Other hosts (e.g. Cubase) implement explicit ARA and non-ARA plug-in insert points. <br>                               The <a href="https://helpcenter.celemony.com/M5/doc/melodyneStudio5/en/M5tour_StudioOneARA_InsertVorbereitungen3?env=studioOne">Melodyne online manual</a> provides a comprehensive description of various ARA host behaviors. <br>                              </p>
<p>The distinction between ARA and non-ARA variant also extends to persistency: settings from the ARA version cannot be loaded by the non-ARA version and vice versa. Host documents must encode this distinction accordingly in order to be properly restorable. Documents created before the adoption of ARA must keep using the non-ARA variant. <br>                              </p>
<p>There are several other, more subtle semantic distinctions between ARA and non-ARA plug-in usage, they will be noted throughout this document and in the ARA headers. <br>                              </p>
<h2><a class="anchor" id="sec_LanguageAndPlatformSupport"></a>
Language And Platform Support</h2>
<p>For highest compatibility with existing code and to work with all established plug-in formats, the ARA interface is defined in C99, making it easy to interface with other programming languages as needed. <br>                               Because of its widespread use, extra effort was put into convenient C++11 compatibility (namespaces, constants definitions, calling conventions). The supporting library code wraps the ARA API into C++11 classes and utilities. <br>                              </p>
<p>The ARA API itself does not depend on a certain compiler or OS version. <br>                               The ARA library code heavily relies on C++11 and is therefore set up to compile with Xcode 8 for Mac OS X 10.9 or higher and with Microsoft Visual Studio 2017 for Windows 8.1 or higher. <br>                               We've also experimented with compiling the ARA SDK on Linux (Ubuntu 18.0.4) using gcc 8.3 and clang 7.0 with the provided CMake files - see ARA_Examples/CMakeLists.txt for more details. <br>                               While largely agnostic to the underlying platform, only x86 and x86-64 compatible systems are currently tested and supported. ARM64 will be supported in a future update. <br>                              </p>
<p>In order to provide a compiler-independent binary-compatible API, ARA needs to use types with defined sizes. It does so by specifying typedefs for all data types used in the API. These typedefs are set up depending on the compiler in use to ensure compatible data type sizes. <br>                               There are some implications of this: for one, enum types cannot be used in the API directly, because their size is implementation-dependent. Instead, for each enum a matching integer type is introduced in the API, which must always carry values from the enumeration only. <br>                               Along the same lines, we're not using <code>stdbool.h</code>, but rather define a fixed-sized <a class="el" href="group___boolean__values.html">ARABool</a> for the API. <br>                              </p>
<h2><a class="anchor" id="autotoc_md1"></a>
API Versioning</h2>
<p>Most structs in the ARA API contain a member indicating their size. This is used to provide a simple versioning scheme for extending the API in a backwards-compatible way. Later revisions can append new members at the end of the struct and define default behavior that is to be assumed whenever the struct does not yet contain the new members at runtime. <br>                               Basing the versioning on the size of the struct rather than defining abstract API version numbers has the advantage of more readable code, because as a programmer you don't need to know which version of the struct contains which fields. Instead, you explicitly check for the presence of a given field by comparing the struct size, which is close to what <code>-respondsToSelector:</code> allows for in Objective-C and similar to COM's <code>queryInterface()</code>. <br>                              </p>
<p>In addition to this backwards-compatible versioning via struct sizes, ARA also features API generations, which allow for incompatible API changes should the need arise. <br>                               For more information, see the <a class="el" href="group___versioned__structs.html">Versioned Structs</a> and <a class="el" href="group___a_p_i__generations.html">API Generations</a>, respectively, of the API reference.</p>
<h2><a class="anchor" id="sec_ARA_Object_References"></a>
Objects And Object References</h2>
<p>While written in C, ARA uses an object-oriented design that can be easily bridged to and from C++ and other object oriented languages. ARA objects are identified at runtime using strongly typed, opaque references called <a class="el" href="group___object___references.html#ga42fe0242eba7db0b27b9c6045b5b0aff">ARA...Ref</a> for plug-in objects and <a class="el" href="group___object___references.html#ga6ef66a60f0e182cdb10a6643774d757a">ARA...HostRef</a> for host objects. These references are pointer-sized identifiers bound to a certain object class. <br>                               In typical implementations such as in the accompanying example code, the ARA references hold the C++ <code>this</code> pointer, but it also may contain an index into an array of structs or whatever else fits the given implementation. <br>                              </p>
<p>Each <a class="el" href="group___object___references.html#ga42fe0242eba7db0b27b9c6045b5b0aff">ARA...Ref</a> only has a meaning on the plug-in side; on the host side it is an opaque token that is simply passed along whenever calling into the plug-in. The same principle applies the other way around for <a class="el" href="group___object___references.html#ga6ef66a60f0e182cdb10a6643774d757a">ARA...HostRef</a>. For example, objects that represent areas of audio playback are referred to on the plug-in side via a <a class="el" href="group___model___playback___region.html#ga9f34c4bb513bc9b514d346c531b7fe8b">ARAPlaybackRegionRef</a>, whereas the equivalent objects in the host are referred to via a <a class="el" href="group___model___playback___region.html#ga69daf0d4cf4ca3cf9acf2874ca1dc682">ARAPlaybackRegionHostRef</a>. <br>                               Actual ARA object instances are never shared between the host and the plug-in. Instead, the host uses dedicated functions to create ARA objects on the plug-in side, which are then addressed using their opaque <a class="el" href="group___object___references.html#ga42fe0242eba7db0b27b9c6045b5b0aff">ARA...Ref</a>, and vice versa (<a class="el" href="group___object___references.html#ga6ef66a60f0e182cdb10a6643774d757a">ARA...HostRef</a>). Amongst other benefits, this allows for running the plug-ins and the host in separate address spaces. <br>                               The caller of the creation function is responsible for properly managing the life time of the <a class="el" href="group___object___references.html">ARARef / ARAHostRef</a>. and its associated ARA object by calling a matching destruction function when appropriate. Typically, this is easy to implement because both the host and the plug-in already have a life-time management for their internal model objects in place, and the additional management of the corresponding objects on the other side can be directly coupled to this existing code. <br>                              </p>
<p>Following the <a href="https://en.wikipedia.org/wiki/Model_view_controller">Model-View-Controller</a> pattern, ARA distinguishes between abstract model objects that are hardly more than "plain-old-data" types and operational controller objects that manipulate those model objects and the relationships between them. <br>                               Defining the API boundary at controller level and representing the model objects with abstract tokens allows for maximum flexibility when interfacing ARA with a given code base: instead of having to code a set of predefined ARA model classes, existing infrastructure can be leveraged to represent the ARA model data with only minimal glue code at controller level translating between the ARA abstractions and the existing implementation. <br>                              </p>
<p>The interface of any given controller object is expressed as a set of function pointers, which are defined according to the class of the object. This matches the concept of e.g. the <code>vtable</code> in C++, but there is no direct binary compatibility because <code>vtables</code> contain private, language and compiler implementation dependent data. Instead, ARA defines simple C structs containing the function pointers. <br>                              </p>
<p>For an example of a simple interface, see the <a class="el" href="group___host___playback___controller___interface.html#struct_a_r_a_playback_controller_interface" title="Host interface: playback controller. As with all host interfaces, the function pointers in this struc...">ARAPlaybackControllerInterface</a>.</p>
<h1><a class="anchor" id="sec_ARA_Document_Controller"></a>
The ARA Document Controller</h1>
<p>In the established plug-in standards, no model data is shared between the individual plug-in instances. This works well because the access to the audio data or the timing information is always limited to the small window of the current realtime rendering block. <br>                               With ARA however, this window is lifted and thus much more information is exchanged between the host and the plug-ins. Creating copies of this potentially memory-intense information for each plug-in instance is too expensive, so ARA avoids this by establishing the concept of a document which contains the model graph and is shared between compatible plug-in instances. ARA documents typically represent a "song" or "project" within the host, and hosts can support multiple documents simultaneously. <br>                              </p>
<p>The ARA document is not managed by any of the plug-in instances, but rather by a new, separate entity called the <a class="el" href="group___plug-_in___document___controller.html">ARA document controller</a> in a 1:1 relationship. The document controller is the gateway to the ARA model graph - when plug-in instances are created via the companion API to perform tasks such as rendering audio or displaying model data in the UI, they will use the document controller to access the model graph. <br>                               It is possible to use an ARA document controller without any accompanying plug-in instance, e.g. when utilizing the analysis capabilities of a plug-in like Melodyne to extract tempo information from a set of audio files in a background batch process. Using a companion plug-in instance without binding it to a document controller on the other hand will disable all its ARA features because the plug-in will have no access to model data for rendering or display. <br>                              </p>
<p>To create instances of an ARA document controller, the plug-in provides a static factory. Besides creating actual controller instances, the factory also provides meta information about the controller that is needed e.g. to find the right controller class when loading archives or to find out whether a given controller class is capable of performing a particular background analysis that the host wants to make use of. <br>                               If ARA wasn't using established plug-in APIs, then this factory would be the starting point for the contract between plug-in and host. With the companion plug-in APIs in place, ARA adds a call to retrieve the matching ARA factory for a given companion plug-in instance. By supporting this call, a plug-in also indicates towards the host that it is capable of ARA in the first place. <br>                               Where the companion API allows for it, ARA further defines an additional entry into the binary to access the factory independently from any plug-in instances. This may be the preferred method of discovery where available. <br>                              </p>
<h1><a class="anchor" id="sec_ModelGraphOverview"></a>
ARA Model Graph Overview</h1>
<p>Once the <a class="el" href="group___plug-_in___document___controller.html">ARADocumentController</a> is established, the host interacts with it to publish the model graph it wants the ARA plug-in instances to process. This graph exposes the relevant subset of host model objects to the plug-in, and each of these objects is mirrored inside the plug-in. The connection between the host and the plug-in representation of each object is established via the opaque <a class="el" href="ara_design_overview.html#sec_ARA_Object_References">ARA object references</a> discussed above. <br>                               The structure of the ARA model graph is entirely controlled by the host: creating and removing objects or changing connections between them is never done by the plug-in, only by the host. <br>                              </p>
<p>The following provides an overview of the ARA model graph:</p>
<p> <object data="ARA_objects_graph.pdf#toolbar=0&navpanes=0&scrollbar=0" width=" 1050px" height=" 796px">                                        </object>                                        </p>
<p>The root object of the ARA model graph is the <a class="el" href="group___model___document.html">ARADocument</a>, managed by an <a class="el" href="group___plug-_in___document___controller.html">ARADocumentController</a> in a 1:1 relationship as discussed above. <br>                               Each <a class="el" href="group___model___document.html">ARADocument</a> can hold a set of <a class="el" href="group___model___audio___source.html">ARAAudioSources</a>, representing sampled audio data (such as an audio file) owned by the host. The audio source sample data should be considered immutable - while updating it is technically possible, doing so will typically invalidate all dependent data in the plug-in, described below. <br>                               The sample data will usually be analyzed by the ARA-enabled plug-in as needed to accomplish its tasks. The host also has the option to explicitly trigger any analysis it may need to implement certain features. <br>                               Note that plug-ins may feature a user interface to fine-tune analysis parameters or to manually override any incorrect analysis results. For an example of this, see <a href="https://helpcenter.celemony.com/M5/doc/melodyneStudio5/de/M5tour_NA_Mode_1?env=studioOne">Melodyne's online manual</a>. <br>                              </p>
<p>Based on the audio source analysis, the plug-in will create an internal representation of the content which is the foundation for any edits that the user can apply to the material. These subsequent edits are plug-in-specific and controlled through the plug-in UI exclusively. Their associated states are encapsulated in <a class="el" href="group___model___audio___modification.html">ARAAudioModification</a> objects which are opaque towards the host. <br>                               Each audio modifications can be thought of as mini-arrangement of the sample data of the underlying audio source - it contains the actual creative work of the user. <br>                               Because of the tight coupling with the analysis of the underlying audio source samples, audio modification states are typically invalidated whenever these samples are updated, resulting in a loss of productive work. Modifying the audio source samples should therefore be avoided whenever possible. <br>                              </p>
<p>Note that while an audio source covers a limited time range, an audio modification is conceptually unlimited in time - the user freely can re-arrange the audio source data, and in that process it's possible to copy&amp;paste data before the start or behind the end of the original audio source. The host should therefore allow the user to "resize" audio modifications arbitrarily to cover any time range. <br>                              </p>
<p>It is possible to create more than one audio modification per audio source, so that the user can create various musical variations of the same audio source material. <br>                               A comparable pattern is already established in many advanced MIDI editors: when duplicating MIDI data inside an arrangement, the user often has the option to either create an alias that will reflect all later edits applied to the original data, or to create an individual copy of the data that will no longer be influenced by changes to the original. In terms of the ARA model, an individual copy would be represented by a new audio modification being created ("cloned"), whereas an alias would simply refer to the original modification. <br>                              </p>
<p>To arrange the modified audio within the song, the host will create <a class="el" href="group___model___playback___region.html">ARAPlaybackRegions</a> which describe segments of audio modifications that are to be rendered in a specific timing context. Playback regions can be augmented with specific transformations like time-stretching and content based fades, as detailed later on. Such a playback region usually matches objects termed "audio region" or "audio event" in current DAWs. <br>                              </p>
<p>Playback regions can be grouped by the host into <a class="el" href="group___model___region___sequences.html">ARARegionSequences</a> - typically this grouping is done according to their arrangement in the song, i.e which "track" or "lane" the regions are on in the song. <br>                               The term region sequence was chosen so it will not collide with the many different usages of the term "track" across existing DAWs: channels in the mixer, lanes in the arrangement, hierarchies/folders of such lanes, or even entire songs. <br>                              </p>
<p>In their arrangements, host usually define a musical map describing changes in tempo and scale or chord progressions. ARA encapsulates this data in an object called an <a class="el" href="group___model___musical___context.html">ARAMusicalContext</a> . Each region sequence (and therefore each region contained in the sequence) is associated with a musical context. <br>                              </p>
<p>The following screenshot demonstrates how Logic Pro maps its internal model to the ARA model graph.</p>
<p> <object data="Logic_Model_Graph.pdf#toolbar=0&navpanes=0&scrollbar=0" width=" 1050px" height=" 350px">                                        </object>                                        </p>
<p>The ARA objects discussed have explicit and well-defined properties that are initialized by the host upon creation - these properties may be updated at any time as long as the updates occur within an edit cycle. For example, hosts may use an edit cycle to update the start and end time of a playback region or the color of a region sequence. <br>                              </p>
<p>Both plug-in and host also have internal data structures that contain much more information about the object, such as the results of the analysis of an audio source inside the plug-in or the signatures of a song timeline inside the host. This content information may or may not be present, and the internal format for it may be completely different in each program. <br>                               To exchange this information between plug-in and host ARA establishes content readers, which are temporary objects used to iterate content information in a normalized format. They will be detailed in a later section of this document. <br>                              </p>
<p>The structure of the model graph and the properties of the objects therein are directly controlled by the host via the document controller, and it also directly notifies the plug-in about whenever it needs to update content information due to user edits in the host. <br>                               If the content on the plug-in side is modified, the plug-in must notify the host accordingly - the host polls for these updates when it is idle. <br>                              </p>
<h1><a class="anchor" id="autotoc_md2"></a>
Exchanging Content Information</h1>
<p>A key feature of ARA is the ability to exchange information about the musical content of ARA objects. This communication can work both ways - for example the host can ask a plug-in to execute an analysis of an audio source and then query its results, but it also can provide the plug-in with information about the audio source up-front, such as the tempo map used when recording the audio. <br>                               Most importantly, the host uses this API facility to describe the content of the musical context in which the playback regions will be rendered in. <br>                              </p>
<p>To suit the very different capabilities and needs of the various plug-ins and hosts, ARA defines a set of content types that may or may not be supported by either the plug-in or the host. Due to the sequential nature of music, each content type is encoded as a series of content events in time. Each event is represented by a particular ARA content struct associated with the content type. <br>                               The most prominent example of an content type are musical notes, which can be described via start, length, average volume and pitch just like MIDI does. ARA defines a basic note event type like so:</p>
<pre class="fragment">typedef struct ARAContentNote
{
    // average frequency in Hz, kARAInvalidFrequency if note has no defined pitch (percussive)
    float frequency;

    // index corresponding to MIDI note number (or kARAInvalidPitchNumber)
    ARAPitchNumber pitchNumber;

    // normalized level: 0.0f (weak) &lt;= level &lt;= 1.0f (strong)
    // This value is scaled according to human perception
    float volume;

    // time marking the beginning of the note (aka "note on" in MIDI), relative to
    // the start of the described object (audio source/playback region)
    ARATimePosition startPosition;

    // time marking the musical/quantization anchor of the note,
    // relative to the start of the note
    ARATimeDuration attackDuration;

    // time marking the release point of the note (aka "note off" in MIDI),
    // relative to the start of the note
    ARATimeDuration noteDuration;

    // time marking the end of the entire sound of the note (end of release phase),
    // relative to the start of the note
    ARATimeDuration signalDuration;
} ARAContentNote;
</pre><p>  <br>                              </p>
<p>The amount of data used to represent content information can be very large. ARA therefore does not transfer all information about all events in a single transaction. Instead, it leverages the common iterator pattern by defining <a class="el" href="group___model___content___readers__and___content___events.html">content event readers</a>. <br>                               Code that wants to read certain content information can use a reader object bound to a given <a class="el" href="group___a_r_a___model___graph.html">ARA model object</a>, <a class="el" href="group___model___content___readers__and___content___events.html#ga24de378fe088e091ac0bdd0467f5bcb8">content type</a> and <a class="el" href="group___model___content___readers__and___content___events.html#struct_a_r_a_content_time_range">time range</a>. This pulling is done in small and fast transactions. <br>                              </p>
<p>To keep the amount of transferred data small, the data structs returned by the content reader are not versioned like other ARA structs. Extending the data provided by the content readers in a new version of ARA will instead be done by simply adding new content types. <br>                              </p>
<p>Besides providing (or not providing) the actual information, it is possible to also specify a quality for it, named "content grade". This is particularly useful when trying to resolve potentially conflicting information such as a plug-in detecting a tempo of 140 bpm when the host claims a tempo of 120 bpm. <br>                               For example, when making up some default value for initializing model data without any correlation to the actual music, such as assuming a default tempo of 120 bpm for a new song, this information would be accordingly qualified as "initial". <br>                               If the values are then determined via an analysis of the material, the grade would be upgraded to "analyzed". If modified by the user, it would become "adjusted". <br>                               There is an even higher grade of quality called "approved" which is typically not achieved by normal editing. Instead, this would be used by content creators to explicitly mark the current state of information as "correct" to prevent further adjustments by end-users. <br>                              </p>
<p>It may be surprising at first that events are counted using an <a class="el" href="group___fixed-size__integers.html#gae89c0d982d17edbe5bac0a55255f38d6">ARAInt32</a>, not an <a class="el" href="group___fixed-size__integers.html#ga146f863d090eb0291cb2f6c4d19c373e">ARASize</a> data type which would extend to 64 bit on the according platforms. However this was done to emphasize that these events are entities that the user must be able to comprehend and manually edit, so 32 bits are way beyond the upper limits applicable here. <br>                              </p>
<h1><a class="anchor" id="autotoc_md3"></a>
Updating The ARA Model Graph</h1>
<p>As explained above, the structure of the ARA model graph is exclusively controlled by the host. Plug-ins will augment the ARA model graph with their internal application specific model data. Changes to this internal data may be explicitly triggered by user edits in the plug-in UI or may happen automatically, i.e when applying the results of an audio source analysis that has been executed in the background. <br>                              </p>
<p>To prevent collisions between these various sources for changes to the graph, ARA requires that changes to the model graph must be applied serially on the main thread (either by applying them on the main thread or by blocking the main thread while applying it from a different thread). <br>                               Furthermore, edits by the host must be grouped into explicit edit cycles during which the plug-ins can suppress any pending internal edits, which is important to keep the undo history in both the host and the plug-in consistent. <br>                              </p>
<p>Here's a code example illustrating the use of an edit cycle if the user renames the current ARA document:</p>
<pre class="fragment">// start the edit cycle
araDocumentController-&gt;beginEditing ();

// update the document name
ARADocumentProperties documentProperties;
documentProperties.structSize = ARA_IMPLEMENTED_STRUCT_SIZE (ARADocumentProperties, name);
documentProperties.name = "Updated Document Name";
araDocumentController-&gt;updateDocumentProperties (&amp;documentProperties);

// end the edit cycle
araDocumentController-&gt;endEditing ();
</pre><p>  <br>                              </p>
<p>Using edit cycles has a number of further benefits. First of all, it defines an explicit window of time (i.e. anytime outside the editing cycle), where both the host and the plug-in are guaranteed to be in sync, and render results thus are well-defined. This is important if a plug-in has some sort of lag between changing the model graph and actually making the results audible, e.g. because it has to update large caches - the plug-in will not return from <a class="el" href="group___plug-_in___document___controller.html#ab4946909515472d8ea4f5f1ee5cac599">endEditing()</a> until these updates are finished. <br>                              </p>
<p>Edit cycles also allow plug-ins to optimize performance when there are interdependencies between ARA objects - updates of their internal model data may be delayed until the end of the editing cycle when the new ARA graph is fully known to suppress unneccessary intermediate calculations. <br>                               Consequently, hosts should take care to group all related graph changes into a single edit cycle where possible instead of implementing multiple edit cycles which each contain only a subset of the changes.. <br>                              </p>
<p>Further, plug-in implementations may have to take special action from <a class="el" href="group___plug-_in___document___controller.html#a73d999e8600d4b9576c3b18fe8dce16f">beginEditing()</a> and <a class="el" href="group___plug-_in___document___controller.html#ab4946909515472d8ea4f5f1ee5cac599">endEditing()</a> to ensure that any ongoing realtime or offline rendering can still access a consistent graph despite the ARA model being edited concurrently. <br>                              </p>
<p>Note that access to audio source samples can be enabled or disabled outside of an edit cycle because this is considered a controller operation not a model edit - see the <a class="el" href="ara_design_overview.html#sec_AudioAccessAndThreading">audio access</a> section for more information. <br>                              </p>
<h1><a class="anchor" id="autotoc_md4"></a>
ARA Model Persistency</h1>
<p>When archiving an ARA model graph, three interconnected parts must be preserved: the host internal data, the resulting ARA graph structure shared between host and plug-in, and the plug-in internal data that is attached to it. As discussed above, the ARA graph structure is described using <a class="el" href="ara_design_overview.html#sec_ARA_Object_References">runtime object references</a>. When restoring an ARA archive, hosts will first restore their internal model, then re-create the ARA graph. Once these ARA objects are created, the plug-in will restore their internal data. <br>                               Since the runtime references have changed since the graph was stored, the plug-in needs a way to map stored state into the newly created objects. The host therefore must define a unique persistent ID for each persistent ARA object in that object's properties. Both host and plug-in must save this ID alongside their respective data structures and use it when restoring the graph. <br>                              </p>
<p>To preserve storage space and ease the implementation, only those ARA objects are persistent that contain information that can be modified in the plug-in. For example, the musical context is defined and edited on the host side only. Therefore it can always be re-created from the host state when loading the document. The same goes for playback regions and region sequences. <br>                               On the other hand, audio source state containing the analysis results, and audio modification state containing the user edits need to be persistent. <br>                              </p>
<p>ARA model graphs may be rather huge when including the internal data on both sides, thus the ARA API was designed to deal with large archives efficiently. To avoid high temporary memory peaks, the data is not necessarily transmitted in one large data block. Instead, ARA uses a simple stream-like API that allows to read/write data in smaller chunks. <br>                               The stream should be both read and written in a consecutive order whenever possible. In some cases however, repositioning is inevitable, so the host must support it. <br>                               Because of its size and complexity, loading and storing an ARA graph may take a noticeable amount of time. Therefore ARA allows for displaying a progress for both processes. <br>                              </p>
<p>Note that because all model data is stored in the ARA model graph, the persistent data returned per plug-in instance via the companion API will be nearly empty when ARA is enabled. Those companion archives can contain UI settings needed to reload the interface, but no model data. <br>                              </p>
<p>More details about persistency are provided in later chapters of this document: <a class="el" href="implementing_a_r_a.html#sec_ManagingARAArchives">Managing ARA Archives</a> lays out how to deal with versioning and migration of ARA plug-in archives, and <a class="el" href="implementing_a_r_a.html#sec_PartialPersistency">Partial Persistency</a> describes the ARA 2 enhancements that enable hosts to selectively store or restore specific document objects rather than full documents, allowing for features like drag and drop of ARA objects between different host documents. <br>                              </p>
<h1><a class="anchor" id="autotoc_md5"></a>
Host Signal Flow And Threading</h1>
<p>A prerequisite for properly implementing ARA is understanding the signal flow in an ARA-enabled host. Before diving into the specifics of this, let's take a look at the typical playback signal flow in hosts without ARA. <br>                              </p>
<p>From a user's perspective, sections of audio files are arranged along a timeline. These snippets are usually called "region" or "clip" - we're using the term region here. The arrangement includes optional per-region transformations of the audio signal, such as level processing (region gain, fades), time stretching and pitch shifting. Additionally, sample rate conversion may need to be applied if the audio file does not match the playback sample rate. <br>                               The regions are typically grouped onto playback tracks, and the resulting track outputs are then fed into a realtime effects processing and mixing engine. <br>                              </p>
<p>The following diagram illustrates a typical host implementation of these processing steps: <br>                              </p>
<p> <object data="ARA2HowTo_Flow.pdf#toolbar=0&navpanes=0&scrollbar=0" width=" 886px" height=" 470px">                                        </object>                                        </p>
<p>To optimize performance, the processing is usually distributed across a variety of threads with different constraints. The actual implementation differs widely between hosts, but typical host architectures assign threads according to the tasks outlined above: <br>                              </p>
<p> <object data="ARA2HowTo_Threads.pdf#toolbar=0&navpanes=0&scrollbar=0" width=" 923px" height=" 659px">                                        </object>                                        </p>
<p>All user interactions are processed on the main thread, and the model graph is maintained there accordingly. The graphical user interface is also updated from this thread. <br>                              </p>
<p>If the host needs to execute heavy-weight calculations such as the analysis of audio material or an "offline bounce", it may offload these operations onto background worker threads to keep the main thread and user interface responsive. <br>                               The main thread will interrupt these low priority threads as needed to establish a fluid user experience. It depends on the actual host implementation which of tasks are scheduled on the main thread and which are executed by background threads. <br>                              </p>
<p>The CPU critical realtime audio processing during playback is normally handled by a set of dedicated high priority render threads. These render threads may interrupt all other threads at any point, but the render calls of each plug-in instance are only called from a single render thread at any time. <br>                               In order to reliably meet their realtime constraints, these render threads must adhere to appropriate coding practices - most notably they must not be waiting for any shared resources such as system memory allocations. <br>                              </p>
<p>To achieve low latency when processing live input signals, small audio buffers must be used and the rendering must happen as close as possible to the current playback time position. <br>                               Playback signals on the other hand can be rendered with much larger buffers and ahead of time, which considerably decreases CPU usage and makes the processing less vulnerable to dropouts. In fact, they can be rendered so early that they may not even need to obey strict realtime requirements. <br>                               Host accordingly tend to split the rendering between two groups of rendering threads: the semi-realtime playback track processing threads and the realtime effect processing and mixing threads. <br>                              </p>
<p>In addition to these rendering threads, hosts typically create another thread dedicated entirely to load the audio file data from disk as needed for rendering. <br>                               This thread has to know in advance what data will be needed for rendering "soon", so that it has enough time to fetch it. This information is typically provided by some sort of sequencer that parses the model and handles the timely scheduling of such audio I/O requests. The scheduling may be executed on a dedicated thread or integrated into the track processing threads. <br>                              </p>
<h1><a class="anchor" id="autotoc_md6"></a>
Inserting ARA Into The Signal Flow</h1>
<p>While common plug-ins operate on blocks of realtime signal that can change arbitrarily between each render call, ARA-enabled plug-ins have no realtime inputs. Instead, they rely on random access to a conceptually static input signal (which can be deliberately updated by the host if needed.) <br>                               They are therefore perfectly suited to be processed by the track processing threads of the render engine instead of the "traditional" realtime effect processing and mixing threads. <br>                              </p>
<p>Depending on their capabilities and configuration, ARA-enabled plug-ins will replace some of the region transformations applied by the host, such as time stretching or sample rate conversion. <br>                               Since the region transformation performed by the ARA-enabled plug-in can include any arbitrary rearrangement of the original audio signal, the plug-in also is responsible for scheduling proper audio source sample reading ahead of time, while delegating the actual I/O operation to the host. The host will no longer stream the files through its playback engine. <br>                              </p>
<p>Due to that setup, an ARA-enabled plug-in needs to be the first plug-in in any serial rendering chain. It is inserted before any other operation associated with the "region"/"event" (such as fades, volume or mute) are applied. This may not be possible to easily implemented for all region operations that the host allows for (i.e. reversing the audio signal) - in that case, the affected operations must either be bounced to the audio source before adding the ARA plug-in, or disabled while ARA is in use. <br>                               As discussed above when introducing the <a class="el" href="ara_design_overview.html#sec_ModelGraphOverview">ARA model graph</a>, frequent updating audio source samples while ARA is in use should be avoided to prevent re-analysis and potential loss of any related user edits. <br>                               To that extent, it is not feasible to stack ARA effects without freezing/bouncing all but the top-of-stack effects. <br>                              </p>
<p>The way ARA is injected into the signal flow also has implications on the bypass behavior. If a host bypasses the rendering of an ARA-enabled plug-in, it will need to take care of applying the time stretching as described in the playback region on its own in order not to mess up the timing when bypass is invoked. <br>                               This may or may not be possible depending on the host's capabilities. ARA-enabled plug-ins should thus consider following Melodyne's example and implement a dedicated ARA "compare-with-original" mode. While in compare mode, Melodyne preserves the playback region time transformations, but bypasses any user edits stored in the audio modification. Accordingly applying the time stretching to the original audio source material allows the user to compare its edited version with the original in the context of the song. <br>                              </p>
<p>In addition to their arrangement-based playback processing, ARA-enabled plug-ins can also create preview signals to guide users when editing the transformations in the UI. This could be playing a metronome click when editing timing while the host playback is stopped, or playing back the note currently dragged up and down by the user so that the current target pitch can be heard. <br>                               This obviously is a realtime process which needs to be handled in the mixer, not at track playback level. To allow optimizing for these different rendering tasks, separate render entities are needed. ARA 2 actively supports this by introducing explicit roles that hosts can assign to the companion API plug-in instances that perform the rendering. <br>                              </p>
<h1><a class="anchor" id="sec_PlugInInstanceRoles"></a>
Plug-In Instance Roles</h1>
<p>Beside the two rendering duties discussed above, there are two more fundamental tasks that ARA-enabled plug-ins must implement: exchanging model data with the host, and providing a UI for the user to edit the plug-in specific arrangement transformations. <br>                               While the model is entirely ARA-specific and accordingly maintained through the <a class="el" href="ara_design_overview.html#sec_ARA_Document_Controller">ARA document controller</a>, the rendering and the UI are implemented via companion API plug-in instances. These instances are toggled into ARA mode by "binding" them to an ARA document controller and its associated model. When binding, the host also assigns the specific roles that it wants the <a class="el" href="group___plug-_in___extension.html">ARA plug-in instance</a> to assume: <br>                              </p><ul>
<li><a class="el" href="group___plug-_in___extension.html#ggadb888a1dc7f658281705411c7b4c253ea5f7f13e0744f8a3b1a0167aef4cc91ca">Playback Renderer</a></li>
<li><a class="el" href="group___plug-_in___extension.html#ggadb888a1dc7f658281705411c7b4c253ea43bac0cdb9433838cab4b79734aa4486">Editor Renderer</a></li>
<li><a class="el" href="group___plug-_in___extension.html#ggadb888a1dc7f658281705411c7b4c253eac033ffe4d4ae6821fe05a418929cf093">Editor View</a></li>
</ul>
<p>The roles also define the semantics of how to use the related companion API calls (see detailed API documentation). <br>                               For example, ARA playback renderes do not operate on realtime input - this is true both for the actual audio signal and for realtime parameter changes - since ARA is an offline API at its heart, any companion API parameters should not be used when ARA is active. <br>                              </p>
<p>Depending on the host architecture, any plug-in instance may be assigend any combination of roles. A very natural setup keeps all three responsibilities completely separate, meaning each plug-in instance is assigned a single specific role. This is the case in the ARA implementation in Cubase/Nuendo: <br>                              </p>
<p> <object data="ARA2HowTo_Host1.pdf#toolbar=0&navpanes=0&scrollbar=0" width=" 1008px" height=" 659px">                                        </object>                                        </p>
<p>Here's another example that closely resembles the original ARA 1 implementation in Studio One, where each plug-in instance assumes all three roles: <br>                              </p>
<p> <object data="ARA2HowTo_Host2.pdf#toolbar=0&navpanes=0&scrollbar=0" width=" 999px" height=" 659px">                                        </object>                                        </p>
<p>Comparing this host architecture to the previous one, the most important difference is that in the first architecture the playback rendering can be done in non-realtime, "offline" mode, whereas the in the second example it must be performed in realtime - ARA-enabled plug-ins need to deal properly with both modes. <br>                              </p>
<h1><a class="anchor" id="sec_AudioAccessAndThreading"></a>
Audio Access And Threading</h1>
<p>A key feature of ARA is the multi-threaded, high-performance access from the plug-in to the samples of the host's <a class="el" href="group___model___audio___source.html">ARAAudioSource</a>. The API provides a synchronous (and thus potentially blocking) service that is well-suited for UI operations from the main thread or for background analysis jobs. <br>                               However these calls must not be used from realtime threads because they have an undefined execution time. Instead, plug-ins have to implement a non-realtime caching thread that fetches the audio source samples ahead of time so that they are available when the realtime renderer needs them, just like the host does internally for the non-ARA signal paths. <br>                              </p>
<p>To ease the host implementation of the required multi-threaded audio access, ARA defines audio reader objects. Each of the audio readers may only be used by one thread at a time, so its interface is single-threaded. The plug-in will create as many audio readers as it has threads that need to read a given audio source concurrently. <br>                              </p>
<p>Accessing the audio sources may not be possible at all times - for example when loading documents, the host may need to prepare some internal resources before samples can be provided. To manage such needs, the plug-in's <a class="el" href="group___plug-_in___document___controller.html">document controller</a> provides a synchronous call <a class="el" href="group___plug-_in___document___controller.html#a25219110cde06efeceeda830a23be94a">enableAudioSourceSamplesAccess()</a>. <br>                               While access is disabled, the plug-in must not use any of the audio readers. This specifically implies that when access is turned off, the plug-in must block the call until all reader threads have acknowledged this. <br>                               </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
